{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following installs once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install -U kfserving==0.2.0 lightgbm \n",
    "    !pip install -U azure\n",
    "    !pip uninstall -y mlrun\n",
    "    !pip install git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never run nuclio functions in your notebooks, please uncomment and run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install nuclio-jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuclio code section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages available to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install git+https://github.com/mlrun/mlrun.git@development\n",
    "pip install kfserving==0.2.0 --upgrade\n",
    "pip install azure\n",
    "pip install numpy\n",
    "pip install lightgbm\n",
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfserving\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import List\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = '/User/mlrun/lightgbm'\n",
    "MODEL_NAME = 'lightgbm.model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBoostModel(kfserving.KFModel):\n",
    "    def __init__(self, name: str, model_dir: str, booster: lgb.LGBMClassifier = None):\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.model_dir = model_dir\n",
    "        if booster:\n",
    "            self.ready = True\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model from KubeFlow storage.\n",
    "        \"\"\"\n",
    "        model_file = os.path.join(\n",
    "            kfserving.Storage.download(self.model_dir), MODEL_NAME)\n",
    "\n",
    "        self.classifier = joblib.load(model_file)\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\n",
    "        \n",
    "        :param body : A list of observations, each of which is an 1-dimensional feature vector.\n",
    "            \n",
    "        Returns model predictions as a `List`, one for each row in the `body` input `List`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            feats = np.asarray(body['instances'])\n",
    "            result: np.ndarray = self.classifier.predict(feats)\n",
    "            return result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to predict {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_model_server, mount_v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = new_model_server('lgbm_inference_model', \n",
    "                      models={'lgbm_joblib': TARGET_PATH}, \n",
    "                      model_class='LGBoostModel').apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.spec.no_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-09 12:01:14,772 deploy started\n",
      "[nuclio] 2020-01-09 12:03:44,077 (info) Build complete\n",
      "[nuclio] 2020-01-09 12:03:51,163 done updating lgbm-inference-model, function address: 3.20.71.254:30906\n"
     ]
    }
   ],
   "source": [
    "#fn.verbose=True\n",
    "addr = fn.deploy(project='github-demos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data from the test set\n",
    "features = pq.read_table(os.path.join(TARGET_PATH, 'xtest.parquet')).to_pandas().iloc[:3, :]\n",
    "labels = pq.read_table(os.path.join(TARGET_PATH, 'ytest.parquet')).to_pandas().iloc[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\"instances\": features.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.post(addr + '/lgbm_joblib/predict', json=event)\n",
    "json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Estimated Model Object \n",
    "\n",
    "Here we simply grab the estimated model file created on the [kubeflow pipeline](kubeflow%20pipeline.ipynb), load it, and run a test matrix through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_file = os.path.join(TARGET_PATH, MODEL_NAME)\n",
    "lgbm_model = joblib.load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvals = np.asarray(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model.predict(testvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
