{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Using Serverless Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mlrun``` is an open-source Python package that provides a framework for running machine learning tasks transparently in multiple, scalable, runtime environments.  ```mlrun``` provides tracking of code, metadata, inputs, outputs and the results of machine learning pipelines. \n",
    "\n",
    "In this notebook we'll take a look at using ```mlrun```, ```nuclio``` and KubeFlow to assemble a data acquisition and model training pipeline and deploy it as a nuclio serverless function with an API endpoint for testing.  The focus here is on how all the components interact, and less on the boosting model and its optimization for the Higgs dataset.\n",
    "\n",
    "#### **notebook take-aways**\n",
    "* write and test reusable and replaceable **[MLRun](https://github.com/mlrun)** components in a notebook, file or github repository\n",
    "* store and load models\n",
    "* run the components as a **[KubeFlow](https://www.kubeflow.org/)** pipeline\n",
    "\n",
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[Nuclio code section](#nuclio-code-section)<br>**\n",
    "    - [nuclio's ignore notation](#nignore)<br>\n",
    "    - [function dependencies](#function-dependencies)<br>\n",
    "    - [utility functions](#utilities)<br>\n",
    "**[Pipeline methods](#pipeline-methods)<br>**\n",
    "    - [acquire](#acquire)<br>\n",
    "    - [train](#train)<br>\n",
    "**[Testing locally](#testing)<br>**\n",
    "**[Create a deployment image](#image)<br>**\n",
    "**[Test remotely](#remote)<br>**\n",
    "**[Create a KubeFlow Pipeline](#pipeline)<br>**\n",
    "**[Compile the pipeline](#compile-the-pipeline)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio-code-section\"><a>\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nignore\"></a>\n",
    "### nuclio's _**ignore**_ notation\n",
    "\n",
    "You'll write all the code that gets packaged for execution between the tags ```# nuclio: ignore```, meaning ignore all the code here and above, and ```# nuclio: end-code```, meaning ignore everything after this annotation.  Methods in this code section can be called separately if designed as such (```acquire```, ```split```, ```train```, ```test```), or as you'll discover below, they are most often \"chained\" together to form a pipeline where the output of one stage serves as the input to the next. The **[docs](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** also suggest another approach: we can use ```# nuclio: start``` at the first relevant code cell instead of marking all the cells above with ```# nuclio: ignore```.\n",
    "\n",
    "See the **[nuclio-jupyter](https://github.com/nuclio/nuclio-jupyter)** repo for further information on these and many other **[nuclio magic commands](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** that make it easy to transform a Jupyter notebook environment into a platform for developing production-quality, machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lines _**should be in the same cell**_ and mark the start of your mchine learning coding section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='function-dependencies'></a>\n",
    "### function dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installs made in the section **[Setup](#Setup)** covered the Jupyter environment within which this notebook runs.  However, we need to ensure that all the dependencies our nuclio function relies upon (such as ```matplotlib```, ```sklearn```, ```lightgbm```), will be available when that code is wrapped up into a nuclio function _**on some presently unknown runtime**_.   Within the nuclio code section we can ensure these dependencies get built into the function with the ```%nuclio cmd``` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "rm /conda/lib/python3.6/site-packages/seaborn* -rf\n",
    "pip uninstall -y mlrun\n",
    "pip install -U -q mlrun\n",
    "pip install -U -q kfp\n",
    "pip install -U -q pyarrow\n",
    "pip install -U -q pandas\n",
    "pip install -U -q matplotlib\n",
    "pip install -U -q seaborn\n",
    "pip install -U -q scikit-learn\n",
    "pip install -U -q lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a standard base image here, however the build step can be shortened by preparing images with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from os import path, makedirs\n",
    "import json\n",
    "from cloudpickle import load, dump\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from typing import IO, AnyStr, TypeVar, Union, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (roc_curve, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import seaborn as sns\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pyarrow import Table\n",
    "\n",
    "from mlrun.artifacts import TableArtifact, PlotArtifact\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='utilities'></a>\n",
    "### utility functions\n",
    "\n",
    "Logging and getting tables from the artifact store is something we do often in this demo, so we provide these utilities for logging and extracting tables from the artifact store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_table(ctxtable: DataItem) -> Table:\n",
    "    \"\"\"deserialize table in artifact store\n",
    "    \n",
    "    :param ctxtable:  table in the artifact store\n",
    "    \"\"\"\n",
    "    blob = BytesIO(ctxtable.get())\n",
    "    return pd.read_parquet(blob, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_context_table(\n",
    "    context: MLClientCtx,\n",
    "    target_path: str,\n",
    "    key: str,\n",
    "    table: pd.DataFrame\n",
    ") -> None:\n",
    "    \"\"\"Log a table in the artifact store.\n",
    "    \n",
    "    The table is written as a parquet file, and its target\n",
    "    path is saved in the context.\n",
    "    \n",
    "    :param context:      the function context\n",
    "    :param target_path:  location (folder) of our DataItem\n",
    "    :param key:          name of the object in the artifact store\n",
    "    :param table:        the object we wish to store\n",
    "    \"\"\"\n",
    "    filepath = path.join(target_path, key + '.parquet')\n",
    "    pq.write_table(pa.Table.from_pandas(table), filepath)    \n",
    "    context.log_artifact(key, target_path=filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```train```\n",
    "We have used only 2 parameters for demonstration purposes, ```learning_rate``` and ```num_leaves```, see **[LightGBM Parameters](https://lightgbm.readthedocs.io/en/latest/Parameters.html#parameters)** for\n",
    "more detail on the other parameters available and their default values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lgbm_model(\n",
    "    context: MLClientCtx,\n",
    "    model,\n",
    "    data,\n",
    "    header: List = [],\n",
    "    target_path: str = '',\n",
    "    name: str = '',  # with file extension\n",
    "    key: str = 'model',\n",
    "    exp_labels: dict = {}\n",
    "):\n",
    "    \"\"\"log a classifier model to the artifact store\n",
    "    \n",
    "    :param context:       function context\n",
    "    :param model:         estimated model\n",
    "    :param history:       training-validation metrics\n",
    "    :param data:          train and test data\n",
    "    :param header:        features labels\n",
    "    :param target_path:   destintion folder for file artifacts\n",
    "    :param name:          name of model file (or, prefix to model files)\n",
    "    :param key:           key of model in artifact store\n",
    "    :param labels:        model artifact labels\n",
    "    \n",
    "    Save an estimated model along with metadata, it's training-validation metrics \n",
    "    history and plots, roc curve, confusion matrix and feature importances.  \n",
    "    \"\"\"\n",
    "    def _gcf_clear(plt):\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()        \n",
    "    \n",
    "    def plot_validation(train_metric, valid_metric):\n",
    "        \"\"\"Plot train and validation loss curves from a metrics table in an\n",
    "        artifact store.\n",
    "\n",
    "        These curves represent the training round losses from the training\n",
    "        and validation sets.\n",
    "        :param train_metric:    train metric\n",
    "        :param valid_metric:    validation metric\n",
    "        \"\"\"\n",
    "        plt.plot(train_metric)\n",
    "        plt.plot(valid_metric)\n",
    "        plt.title(\"training validation results\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.legend([\"train\", \"valid\"])\n",
    "        fig = plt.gcf()\n",
    "\n",
    "        plotpath = path.join(target_path, \"history.png\")\n",
    "        plt.savefig(plotpath)\n",
    "        context.log_artifact(PlotArtifact('training-validation-plot', body=fig, target_path=plotpath))\n",
    "\n",
    "        # to ensure we don't overwrite this figure when creating the next:\n",
    "        _gcf_clear(plt)\n",
    "\n",
    "    def plot_roc(y_labels, y_probs):\n",
    "        \"\"\"Plot an ROC curve from test data saved in an artifact store.\n",
    "        :param y_labels:        test data labels\n",
    "        :param y_probs:         test data \n",
    "        \"\"\"\n",
    "        fpr_xg, tpr_xg, _ = roc_curve(y_labels, y_probs)\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.plot(fpr_xg, tpr_xg, label=\"roc\")\n",
    "        plt.xlabel(\"false positive rate\")\n",
    "        plt.ylabel(\"true positive rate\")\n",
    "        plt.title(\"roc curve\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        fig = plt.gcf()\n",
    "\n",
    "        plotpath = path.join(target_path, \"roc.png\")\n",
    "        fig.savefig(plotpath, format=fmt)\n",
    "        context.log_artifact(PlotArtifact('roc', body=fig))\n",
    "\n",
    "        # to ensure we don't overwrite this figure when creating the next:\n",
    "        _gcf_clear(plt)\n",
    "\n",
    "    def plot_confusion_matrix(labels, predictions):\n",
    "        \"\"\"Create a confusion matrix.\n",
    "        Plot and save a confusion matrix using test data from a\n",
    "        pipeline step.  The plot is generated usung default arguments.\n",
    "        The present example could be extended by including a parameters `dict`\n",
    "        that is passed through to sklearn's `confusion_matrix`,\n",
    "        `ConfusionMatrixDisplay`, and matplotlib `plot`.\n",
    "        :param labels:          test data labels\n",
    "        :param predictions:     test data predictions\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(labels,\n",
    "                              predictions,\n",
    "                              sample_weight=None,\n",
    "                              labels=axislabels,\n",
    "                              normalize='all')\n",
    "        sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "        plotpath = path.join(target_path, \"confusion.png\")\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(plotpath)\n",
    "        context.log_artifact(PlotArtifact('confusion_matrix', body=fig))\n",
    "\n",
    "        # to ensure we don't overwrite this figure when creating the next:\n",
    "        _gcf_clear(plt)\n",
    "\n",
    "    def plot_importance(model, header: List = []):\n",
    "        \"\"\"Display estimated feature importances.\n",
    "\n",
    "        :param model:       fitted lightgbm model\n",
    "        :param header:      list of feature names\n",
    "        \"\"\"\n",
    "        # create a feature importance table with desired labels\n",
    "        zipped = zip(model.feature_importances_, header)\n",
    "\n",
    "        feature_imp = pd.DataFrame(sorted(zipped), columns=['freq','feature']\n",
    "                                  ).sort_values(by=\"freq\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.barplot(x=\"freq\", y=\"feature\", data=feature_imp)\n",
    "        plt.title('LightGBM Features')\n",
    "        plt.tight_layout()\n",
    "        fig = plt.gcf()\n",
    "        plotpath = path.join(target_path, \"feature-importances.png\")\n",
    "        fig.savefig(plotpath)\n",
    "        context.log_artifact(PlotArtifact('feature-importances-plot', body=fig))\n",
    "\n",
    "        # feature importances are also saved as a table:\n",
    "        tablepath = path.join(target_path, \"feature-importances-table.csv\")\n",
    "        feature_imp.to_csv(tablepath)\n",
    "        context.log_artifact(TableArtifact('feature-importances-table', target_path=tablepath))\n",
    "\n",
    "        # to ensure we don't overwrite this figure when creating the next:\n",
    "        _gcf_clear(plt)\n",
    "\n",
    "    if callable(getattr(model, 'predict_proba')):\n",
    "        ypred_probs = model.predict_proba(data['xtest'])[:, 1]\n",
    "        ypred = np.where(ypred_probs >= 0.5, 1, 0)\n",
    "    else:\n",
    "        ypred = model.predict(data['xtest'])\n",
    "        ypred_probs = None\n",
    "\n",
    "    context.log_result(\"test_accuracy\", float(clf.score(data['xtest'], data['ytest'])))\n",
    "\n",
    "    loss = np.asarray(model.evals_result_['train']['binary_logloss'], dtype=np.float)\n",
    "    val_loss = np.asarray(model.evals_result_['valid']['binary_logloss'], dtype=np.float)\n",
    "\n",
    "    plot_validation(loss, val_loss)\n",
    "    if ypred_probs:\n",
    "        plot_roc(data['ytest'], ypred_probs)\n",
    "    if ypred:\n",
    "        plot_confusion_matrix(data['ytest'], ypred)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plot_importance(model, header)\n",
    "   \n",
    "    # save the model and log  as an artifact\n",
    "    filepath = path.join(target_path, name)\n",
    "    dump(model, open(filepath, 'wb'))\n",
    "    context.log_artifact(key,\n",
    "                         target_path=filepath,\n",
    "                         labels=exp_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    context: MLClientCtx,\n",
    "    src_file: str,\n",
    "    header: DataItem,\n",
    "    test_size: float = 0.1,\n",
    "    train_val_split: float = 0.75,\n",
    "    sample: int = -1,\n",
    "    target_path: str = '',\n",
    "    name: str = '',\n",
    "    key: str = '',\n",
    "    exp_labels = {},  # 'lightgbm_sklearn' if this were a pipeline\n",
    "    verbose: bool = False,\n",
    "    random_state = np.random.RandomState(1),\n",
    "    **sklearn_params\n",
    ") -> None:\n",
    "    \"\"\"Train and save a LightGBM model.\n",
    "    \n",
    "    :param context:         the function context\n",
    "    :param src_file:        ('raw') name of raw data file\n",
    "    :param header:          header artifact\n",
    "    :param test_size:       (0.1) test set size\n",
    "    :param train_val_split: (0.75) Once the test set has been removed the \n",
    "                            training set gets this proportion.\n",
    "    :param sample:          (-1). Selects the first n rows, or select a sample starting\n",
    "                            from the first. If negative <-1, select a random sample from \n",
    "                            the entire file\n",
    "    :param target_path:     folder location of files\n",
    "    :param name:            destination name for model file\n",
    "    :param key:             key for model artifact\n",
    "    :param exp_labels:      metadata dict, some keys are required (type, framework). 'type'\n",
    "                            is either classifier or regressor, 'framework' can be sklearn or not\n",
    "                            (sklearn models have a generic interface)\n",
    "    :param verbose :        (False) show metrics for training/validation steps.\n",
    "    :param random_state:    (1) sklearn rng seed\n",
    "    :param sklearn_params   sklearn keyword params \n",
    "    \"\"\"\n",
    "    # load local data\n",
    "    srcfilepath = path.join(target_path, src_file)\n",
    "    # save only a sample, intended for debugging\n",
    "    if (sample == -1) or (sample >= 1):\n",
    "        # get all rows, or contiguous sample starting at row 1.\n",
    "        raw = pq.read_table(srcfilepath).to_pandas()\n",
    "        labels = raw.pop('labels')\n",
    "        raw = raw.iloc[:sample, :]\n",
    "        labels = labels.iloc[:sample]\n",
    "    else:\n",
    "        # grab a random sample\n",
    "        raw = pq.read_table(srcfilepath).to_pandas().sample(sample*-1)\n",
    "        labels = raw.pop('labels')\n",
    "\n",
    "    x, xtest, y, ytest = train_test_split(raw, labels, train_size=1-test_size, \n",
    "                                          random_state=random_state)\n",
    "   \n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x, y, \n",
    "                                                      train_size=train_val_split, \n",
    "                                                      random_state=random_state)        \n",
    "    \n",
    "    clf = lgb.LGBMClassifier(random_state=random_state,\n",
    "                             verbose=int(verbose == True))\n",
    "\n",
    "    eval_results = dict()\n",
    "\n",
    "    clf.fit(xtrain, \n",
    "            ytrain,\n",
    "            eval_set=[(xvalid, yvalid), (xtrain, ytrain)],\n",
    "            eval_names=['valid', 'train'],\n",
    "            callbacks=[lgb.record_evaluation(eval_results)],\n",
    "            verbose=verbose)\n",
    "    \n",
    "    context.log_result(\"train_accuracy\", float(clf.score(xtrain, ytrain)))\n",
    "    \n",
    "    log_lgbm_model(\n",
    "        context, \n",
    "        clf, \n",
    "        data = {'xtest':xtest, 'ytest':ytest},\n",
    "        target_path=target_path,\n",
    "        header=load(open(str(header), 'rb')),\n",
    "        name=name, \n",
    "        key=key,\n",
    "        exp_labels=exp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **end of nuclio function definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some useful parameters to keep the notebook neat:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVE_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
    "FILE_NAME = 'higgs.parquet'\n",
    "CHUNK_SIZE = 10_000\n",
    "TARGET_PATH = '/User/mlrun/models/'\n",
    "MODEL_NAME = 'lgb-classifier.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGGS_HEADER = ['labels', 'lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude', 'missing_energy_phi',\n",
    " 'jet_1_pt', 'jet_1_eta', 'jet_1_phi', 'jet_1_b-tag', 'jet_2_pt', 'jet_2_eta', 'jet_2_phi', 'jet_2_b-tag', 'jet_3_pt',\n",
    " 'jet_3_eta', 'jet_3_phi', 'jet_3_b-tag', 'jet_4_pt', 'jet_4_eta', 'jet_4_phi', 'jet_4_b-tag', 'm_jj', 'm_jjj', 'm_lv',\n",
    " 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _acquire_ - use an existing github function to acquire and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter-1/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-21 21:42:55,693 database connection is not configured\n",
      "[mlrun] 2020-01-21 21:42:55,694 building image (.mlrun/func-default-arc-to-parquet-latest)\n",
      "FROM python:3.6-jessie\n",
      "RUN python -m pip uninstall mlrun\n",
      "RUN python -m pip install -U -q mlrun\n",
      "RUN python -m pip install -U -q pandas\n",
      "RUN python -m pip install -U -q pyarrow\n",
      "RUN python -m pip install -U -q numpy==1.17.4\n",
      "RUN pip install mlrun\n",
      "\n",
      "[mlrun] 2020-01-21 21:42:55,696 using in-cluster config.\n",
      "[mlrun] 2020-01-21 21:42:55,713 Pod mlrun-build-arc-to-parquet-fzdsd created\n",
      "..\n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name python:3.6-jessie to python:3.6-jessie \n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name python:3.6-jessie to python:3.6-jessie \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:0318d80cb241983eda20b905d77fa0bfb06e29e5aabf075c7941ea687f1c125a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0000] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:0318d80cb241983eda20b905d77fa0bfb06e29e5aabf075c7941ea687f1c125a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0001] Unpacking rootfs as cmd RUN python -m pip uninstall mlrun requires it. \n"
     ]
    }
   ],
   "source": [
    "acquire_job = mlrun.import_function(\n",
    "    'https://raw.githubusercontent.com/yjb-ds/functions/lgbm-serving/fileutils/arc_to_parquet/arc_to_parquet.yaml'\n",
    ").apply(mlrun.mount_v3io())\n",
    "acquire_job.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _train_ - use the notebook train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_job = mlrun.code_to_function(\n",
    "#     name='lgbm_job', \n",
    "#     runtime='job', \n",
    "#     with_doc=False)  #.apply(mlrun.mount_v3io())\n",
    "\n",
    "# lgbm_job.export('/User/repos/functions/serving/train-lgbm.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _train_ - use the github function spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job = mlrun.import_function(\n",
    "    '/User/repos/functions/serving/train-lgbm.yaml'\n",
    ").apply(mlrun.mount_v3io())\n",
    "train_job.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "### Create a KubeFlow Pipeline from our functions\n",
    "\n",
    "Our pipeline will consist of two instead of three steps, ```load``` and ```train```.  We'll drop the ```test```\n",
    "here since at the end of this deployment we can test the system with API requests.\n",
    "\n",
    "For complete details on KubeFlow Pipelines please refer to the following docs:\n",
    "1. **[KubeFlow pipelines](https://www.kubeflow.org/docs/pipelines/)**.\n",
    "2. **[kfp.dsl Python package](https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#module-kfp.dsl)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, the model server file name in the ```new_model_server``` function call below should identical in every respect to the name of the model server notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srvfn = mlrun.new_model_server(\n",
    "    'classifier', \n",
    "    model_class='ClassifierModel', \n",
    "    filename='/User/repos/functions/serving/classifier_server.ipynb')\n",
    "\n",
    "srvfn.apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='LGBM', description='lightgbm classifier')\n",
    "def lgbm_pipeline(learning_rate = [0.1, 0.3], num_leaves = [31, 32]):\n",
    "    acquire_step = acquire_job.as_step(\n",
    "            name='acquire_remote_data',\n",
    "            handler='arc_to_parquet',\n",
    "            params={\n",
    "                'archive_url': ARCHIVE_URL,\n",
    "                'header':      HIGGS_HEADER,\n",
    "                'name':        FILE_NAME,\n",
    "                'target_path': TARGET_PATH},\n",
    "            outputs=['header'], \n",
    "            out_path=TARGET_PATH).apply(mlrun.mount_v3io())\n",
    "    \n",
    "    train_step = lgbm_job.as_step(\n",
    "            name='train_model', \n",
    "            handler='train',\n",
    "            inputs={'header' : acquire_step.outputs['header']},\n",
    "            params={\n",
    "                'src_file':         FILE_NAME,\n",
    "                'sample':           20000,\n",
    "                'test_size':        0.1,\n",
    "                'train_val_split':  0.75,\n",
    "                'target_path':      TARGET_PATH,\n",
    "                'name':             MODEL_NAME,\n",
    "                'key' :             'model',\n",
    "                'num_leaves':       31,\n",
    "                'learning_rate':    0.1,\n",
    "                'verbose':          False,\n",
    "                'labels':          {'type'      : 'classifier',\n",
    "                                    'framework' : 'lightgbm',\n",
    "                                    'mode'      : 'model'}},\n",
    "            outputs=['model'],\n",
    "            out_path= TARGET_PATH).apply(mlrun.mount_v3io())\n",
    "\n",
    "    srvfn.deploy_step(\n",
    "        project='default', \n",
    "        models={'classifier_gen': train_step.outputs['model']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compile the pipeline\"></a>\n",
    "### compile the pipeline\n",
    "\n",
    "We can compile our KubeFlow pipeline and produce a yaml description of the pipeline worflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(lgbm_pipeline, TARGET_PATH + '/mlrunpipe.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following line will run the pipeline as a job::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    lgbm_pipeline, \n",
    "    arguments, \n",
    "    run_name='my classifier run',\n",
    "    experiment_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
