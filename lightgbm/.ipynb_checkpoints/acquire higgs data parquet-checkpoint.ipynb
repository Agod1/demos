{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing HIGGS data as Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[Overview](#overview)**\n",
    "- **[Setup](#setup)**\n",
    "- **[Read and Write Data to a Parquet Table in the Platform](#write-data-to-a-parquet-platform-table)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview\n",
    "\n",
    "The goal of this notebook, in addition to retrieving, processing and storing the HIGGS data set, is to sample parquet writing and reading times in an effort to determine how best to pass the data along the proposed pipeline.\n",
    "\n",
    "**[Parquet](https://parquet.apache.org/)** is a columnar storage format that provides high-density high-performance file organization. For information about reading an writing Parquet files from Python applications, see the **[Arrow's Parquet Documentation](https://arrow.apache.org/docs/python/parquet.html)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Setup\n",
    "\n",
    "Run the following code to import required libraries and ingest CSV data into a pandas DataFrame, which will be converted to a Parquet table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pyarrow numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read remote CSV.GZ file into a pandas DataFrame and display the data and metadata that was read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci = \"https://archive.ics.uci.edu/ml/machine-learning-databases\"\n",
    "higgs_url = \"00280/HIGGS.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_cols = [\"labels\", \"lepton pT \", \"lepton eta \", \"lepton phi \",\n",
    "              \"missing energy magnitude \", \"missing energy phi \", \"jet 1 pt \",\n",
    "              \"jet 1 eta \", \"jet 1 phi \", \"jet 1 b-tag \", \"jet 2 pt \",\n",
    "              \"jet 2 eta \", \"jet 2 phi \", \"jet 2 b-tag \", \"jet 3 pt \",\n",
    "              \"jet 3 eta \", \"jet 3 phi \", \"jet 3 b-tag \", \"jet 4 pt \",\n",
    "              \"jet 4 eta \", \"jet 4 phi \", \"jet 4 b-tag\", \"m_jj\", \"m_jjj\",\n",
    "              \"m_lv \", \"m_jlv\", \"m_bb \", \"m_wbb \", \"m_wwbb\"]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAUTION: downloading gzips, total ~3gb, 5gb decompressed -- the following could take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs = pd.read_csv(os.path.join(uci, higgs_url), header=None, names=higgs_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higgs = pd.read_csv('/v3io/users/admin/repos/demos/lightgbm/data/HIGGS.csv.gz', header=None, names=higgs_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"write-data-to-a-parquet-platform-table\"></a>\n",
    "## Write/Read Data to a Parquet Table in the Platform\n",
    "\n",
    "Write the CSV data that was read into the pandas DataFrame to a Parquet table in a platform data container (i.e., in the distributed file system of the Iguazio Data Science Platform).\n",
    "\n",
    "> **Note:** For information about using the `v3io` or `User` data mounts to reference data in the platform\"s data containers, see [Platform Data Containers](collect-n-explore.ipynb/#platform-data-containers) in the **getting-started/collect-n-explore.ipynb** notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the pandas ```DataFrame``` to a new parquet ```Table``` in the platform's file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = os.path.join('/User', 'projects', 'lightgbm', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.71 s, sys: 622 ms, total: 10.3 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(higgs),\n",
    "    os.path.join(target_path, 'original'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read it back again to local memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 2.67 s, total: 5.53 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "higgs = pq.read_table(os.path.join(target_path, 'original'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 1.76 s, total: 2.79 s\n",
      "Wall time: 321 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>lepton pT</th>\n",
       "      <th>lepton eta</th>\n",
       "      <th>lepton phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>jet 1 pt</th>\n",
       "      <th>jet 1 eta</th>\n",
       "      <th>jet 1 phi</th>\n",
       "      <th>jet 1 b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet 4 eta</th>\n",
       "      <th>jet 4 phi</th>\n",
       "      <th>jet 4 b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.159912</td>\n",
       "      <td>1.013847</td>\n",
       "      <td>0.108615</td>\n",
       "      <td>1.495524</td>\n",
       "      <td>-0.537545</td>\n",
       "      <td>2.342396</td>\n",
       "      <td>-0.839740</td>\n",
       "      <td>1.320683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097068</td>\n",
       "      <td>1.190680</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.822136</td>\n",
       "      <td>0.766772</td>\n",
       "      <td>1.002191</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>0.837004</td>\n",
       "      <td>0.860472</td>\n",
       "      <td>0.772484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.618388</td>\n",
       "      <td>-1.012982</td>\n",
       "      <td>1.110139</td>\n",
       "      <td>0.941023</td>\n",
       "      <td>-0.379199</td>\n",
       "      <td>1.004656</td>\n",
       "      <td>0.348535</td>\n",
       "      <td>-1.678593</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216995</td>\n",
       "      <td>1.049177</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.826829</td>\n",
       "      <td>0.989809</td>\n",
       "      <td>1.029104</td>\n",
       "      <td>1.199679</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.938490</td>\n",
       "      <td>0.865269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700559</td>\n",
       "      <td>0.774251</td>\n",
       "      <td>1.520182</td>\n",
       "      <td>0.847112</td>\n",
       "      <td>0.211230</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>0.052457</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585235</td>\n",
       "      <td>1.713962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.845208</td>\n",
       "      <td>0.987610</td>\n",
       "      <td>0.883422</td>\n",
       "      <td>1.888438</td>\n",
       "      <td>1.153766</td>\n",
       "      <td>0.931279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178030</td>\n",
       "      <td>0.117796</td>\n",
       "      <td>-1.276980</td>\n",
       "      <td>1.864457</td>\n",
       "      <td>-0.584370</td>\n",
       "      <td>0.998519</td>\n",
       "      <td>-1.264549</td>\n",
       "      <td>1.276333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399515</td>\n",
       "      <td>-1.313189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838842</td>\n",
       "      <td>0.882890</td>\n",
       "      <td>1.201380</td>\n",
       "      <td>0.939216</td>\n",
       "      <td>0.339705</td>\n",
       "      <td>0.759070</td>\n",
       "      <td>0.719119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464477</td>\n",
       "      <td>-0.337047</td>\n",
       "      <td>0.229019</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>-0.868466</td>\n",
       "      <td>0.430004</td>\n",
       "      <td>-0.271348</td>\n",
       "      <td>-1.252278</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.652782</td>\n",
       "      <td>-0.586254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752535</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.986917</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>0.576084</td>\n",
       "      <td>0.541427</td>\n",
       "      <td>0.517420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          labels  lepton pT   lepton eta   lepton phi   \\\n",
       "0            1.0    0.869293    -0.635082     0.225690   \n",
       "1            1.0    0.907542     0.329147     0.359412   \n",
       "2            1.0    0.798835     1.470639    -1.635975   \n",
       "3            0.0    1.344385    -0.876626     0.935913   \n",
       "4            1.0    1.105009     0.321356     1.522401   \n",
       "...          ...         ...          ...          ...   \n",
       "10999995     1.0    1.159912     1.013847     0.108615   \n",
       "10999996     1.0    0.618388    -1.012982     1.110139   \n",
       "10999997     1.0    0.700559     0.774251     1.520182   \n",
       "10999998     0.0    1.178030     0.117796    -1.276980   \n",
       "10999999     0.0    0.464477    -0.337047     0.229019   \n",
       "\n",
       "          missing energy magnitude   missing energy phi   jet 1 pt   \\\n",
       "0                          0.327470            -0.689993   0.754202   \n",
       "1                          1.497970            -0.313010   1.095531   \n",
       "2                          0.453773             0.425629   1.104875   \n",
       "3                          1.992050             0.882454   1.786066   \n",
       "4                          0.882808            -1.205349   0.681466   \n",
       "...                             ...                  ...        ...   \n",
       "10999995                   1.495524            -0.537545   2.342396   \n",
       "10999996                   0.941023            -0.379199   1.004656   \n",
       "10999997                   0.847112             0.211230   1.095531   \n",
       "10999998                   1.864457            -0.584370   0.998519   \n",
       "10999999                   0.954596            -0.868466   0.430004   \n",
       "\n",
       "          jet 1 eta   jet 1 phi   jet 1 b-tag   ...  jet 4 eta   jet 4 phi   \\\n",
       "0          -0.248573   -1.092064      0.000000  ...   -0.010455   -0.045767   \n",
       "1          -0.557525   -1.588230      2.173076  ...   -1.138930   -0.000819   \n",
       "2           1.282322    1.381664      0.000000  ...    1.128848    0.900461   \n",
       "3          -1.646778   -0.942383      0.000000  ...   -0.678379   -1.360356   \n",
       "4          -1.070464   -0.921871      0.000000  ...   -0.373566    0.113041   \n",
       "...              ...         ...           ...  ...         ...         ...   \n",
       "10999995   -0.839740    1.320683      0.000000  ...   -0.097068    1.190680   \n",
       "10999996    0.348535   -1.678593      2.173076  ...   -0.216995    1.049177   \n",
       "10999997    0.052457    0.024553      2.173076  ...    1.585235    1.713962   \n",
       "10999998   -1.264549    1.276333      0.000000  ...    1.399515   -1.313189   \n",
       "10999999   -0.271348   -1.252278      2.173076  ...   -1.652782   -0.586254   \n",
       "\n",
       "          jet 4 b-tag      m_jj     m_jjj     m_lv      m_jlv     m_bb   \\\n",
       "0            3.101961  1.353760  0.979563  0.978076  0.920005  0.721657   \n",
       "1            0.000000  0.302220  0.833048  0.985700  0.978098  0.779732   \n",
       "2            0.000000  0.909753  1.108330  0.985692  0.951331  0.803252   \n",
       "3            0.000000  0.946652  1.028704  0.998656  0.728281  0.869200   \n",
       "4            0.000000  0.755856  1.361057  0.986610  0.838085  1.133295   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "10999995     3.101961  0.822136  0.766772  1.002191  1.061233  0.837004   \n",
       "10999996     3.101961  0.826829  0.989809  1.029104  1.199679  0.891481   \n",
       "10999997     0.000000  0.337374  0.845208  0.987610  0.883422  1.888438   \n",
       "10999998     0.000000  0.838842  0.882890  1.201380  0.939216  0.339705   \n",
       "10999999     0.000000  0.752535  0.740727  0.986917  0.663952  0.576084   \n",
       "\n",
       "            m_wbb     m_wwbb  \n",
       "0         0.988751  0.876678  \n",
       "1         0.992356  0.798343  \n",
       "2         0.865924  0.780118  \n",
       "3         1.026736  0.957904  \n",
       "4         0.872245  0.808487  \n",
       "...            ...       ...  \n",
       "10999995  0.860472  0.772484  \n",
       "10999996  0.938490  0.865269  \n",
       "10999997  1.153766  0.931279  \n",
       "10999998  0.759070  0.719119  \n",
       "10999999  0.541427  0.517420  \n",
       "\n",
       "[11000000 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "higgs.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create labels\n",
    "\n",
    "Read specific columns (attributes) from the Parquet table to save bandwidth/memory and accelerate load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.3 ms, sys: 202 ms, total: 278 ms\n",
      "Wall time: 294 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = pq.read_table(os.path.join(target_path, 'original'), columns=[\"labels\",]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.67 s, sys: 5.85 s, total: 9.53 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# too many cols\n",
    "features = pq.read_table(os.path.join(target_path, 'original'), columns=higgs_cols[1:]).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7fb1300fc818>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 29\n",
       "  num_rows: 11000000\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 14736"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = pq.ParquetFile(os.path.join(target_path, 'original'))\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table partitions \n",
    "\n",
    "Since we are using parquet, what are some of the partitioning schemes that make sense for the HIGGS data? In **[An Experimental Evaluation of Large Scale GBDT Systems](https://arxiv.org/pdf/1907.01882.pdf)** the authors provide a lengthy discussion of optimal data partitioning in gradient boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two issues to think about when applying gradient boosting to a big data problem:\n",
    "\n",
    "1. What is an optimal partitioning scheme for the **algorithm and its execution**.\n",
    "2. What is an optimal partitioning scheme for **storage**.\n",
    "\n",
    "The article touches on a number of important considerations concering algorithm choice with different types of big data, the dimensionality and density of the data, indexing and partitioning schemes, sparsity, caching and so on.  We won't go into details here, and strongly recommend it and the many other published research efforts on the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In summary, choosing the right algorithm from a data science perspective often has significant implications for indexing, partitioning and data storage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance\n",
    "\n",
    "We might want to take into account whether our data is balanced or not at this early stage.  In the entire sample we are almost balanced.  We'll revisit this after we make the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 1.86 s, total: 3.1 s\n",
      "Wall time: 446 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "true, false = higgs.to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGGS percent True: 52\n"
     ]
    }
   ],
   "source": [
    "print(f'HIGGS percent True: {int(100*true/(false+true)):n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare train-validation-test data sets\n",
    "\n",
    "In the [kubeflow pipeline](#kubeflow%20pipeline.ipynb) notebook we will do the train-test splits during the training step, and pass the test set to the next step. In the following you can get an idea about the timings in creating the splits, writing and reading the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 2.5 s, total: 15.1 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We split using sklearn.train_trest_split twice to get a validation set:\n",
    "x, xtest, y, ytest = train_test_split(features, labels, train_size=0.9, test_size=0.1)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(x, y, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balance again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-split\n",
      "=====================================\n",
      "HIGGS train percent True: 52\n",
      "HIGGS valid percent True: 53\n",
      "HIGGS test percent True: 52\n"
     ]
    }
   ],
   "source": [
    "print('post-split')\n",
    "print('=====================================')\n",
    "true, false = ytrain.labels.value_counts()\n",
    "print(f'HIGGS train percent True: {int(100*true/(false+true)):n}')\n",
    "true, false = yvalid.labels.value_counts()\n",
    "print(f'HIGGS valid percent True: {int(100*true/(false+true)):n}')\n",
    "true, false = ytest.labels.value_counts()\n",
    "print(f'HIGGS test percent True: {int(100*true/(false+true)):n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**time saving loading separate train/valid and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 1.06 s, total: 12.1 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FEATURES\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(xtrain),\n",
    "    target_path+'/xtrain')    \n",
    "\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(xvalid),\n",
    "    target_path+'/xvalid')    \n",
    "\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(xtest),\n",
    "    target_path+'/xtest')    \n",
    "\n",
    "# LABELS\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(ytrain),\n",
    "    target_path+'/ytrain')    \n",
    "\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(yvalid),\n",
    "    target_path+'/yvalid')    \n",
    "\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(ytest),\n",
    "    target_path+'/ytest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take about 3 seconds to load the train and test sets during the training routine, and since training is often the longest step, this delay will be relatively short and it is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 4.16 s, total: 6.95 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "xtrain = pq.read_table(target_path + '/xtrain')\n",
    "ytrain = pq.read_table(target_path + '/ytrain')\n",
    "xvalid = pq.read_table(target_path + '/xvalid')\n",
    "yvalid = pq.read_table(target_path + '/yvalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our test set is small and loads quickly, we can load it again in the ```test_step``` routines of our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 291 ms, sys: 317 ms, total: 608 ms\n",
      "Wall time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xtest = pq.read_table(target_path + '/xtest')\n",
    "ytest = pq.read_table(target_path + '/ytest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "We won't be needing some of the files created, since they are recreated every time we run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = ['xtest', 'ytest', 'xvalid', 'yvalid', 'xtrain', 'ytrain']\n",
    "\n",
    "for file in del_list:\n",
    "    tgt = os.path.join(target_path, file)\n",
    "    try:\n",
    "        os.remove(tgt)\n",
    "    except Exception as e:\n",
    "        print(f\"error deleting file {tgt} {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "For this particular project, apart from the initial download and conversion into a pandas DataFrame, the longest reads and writes take 2-10 seconds. We will start the pipeline with original parquet file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
