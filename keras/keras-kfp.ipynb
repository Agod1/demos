{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tensorflow-Keras and Scikit-Learn With MLRun**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLRun is an open-source Python package that provides a framework for running machine learning tasks transparently in multiple, scalable, runtime environments.  MLRun provides tracking of code, metadata, inputs, outputs and the results of machine learning pipelines. \n",
    "\n",
    "In this notebook we\"ll compose a pipeline that deploys a classifier model, and uses it as the input in a training and validation step. We'll be working with a synthetic features matrix of dimension 10 million rows by 20 features and a binary label.  The model will be a 2-layer neural net classifier using **[tensorflow-keras](https://www.tensorflow.org/)** (v2.0.0b1), without gpu support.\n",
    "\n",
    "The dataset we create is balanced, however there is a `weight` parameter in the data generator function specifying the fraction of observations that are labeled 0/False. The number of samples and features are also parameters.  The demonstration could be modified easily to allow for a more fine-grained control over the simulated dataset either by adding more parameters or replacing the underlying function altogether.\n",
    "\n",
    "The training and validation step employs a scikit learn `Pipeline` to perform feature engineering. Some of the feature engineering needs to be done _**after**_ the train-valid-test set split. In some preprocessing scenarios we might estimate a data transformation on the training set before model training, and then apply the estimate to the validation and test sets before prediction. Since we need to perform the same transformation pre-inference, all pipeline model steps are stored.\n",
    "\n",
    "Serializing models can be challenging for number of reasons:  a pipeline with multiple steps may require just as many encoding and decoding routines--applying Python's `pickle` to a Keras model that has been wrapped in a scikit-learn api fails.  Since we have the model architecture in a class definition, all we need to do is save the weights.  Some steps in a pipeline may have no internal state to store, while others can be stored and loaded using `pickle`.  Most of it all boils down to storing dicts/json with numpy objects.\n",
    "\n",
    "One of the upsides of the present architecture is that we can mix many simulations of data with a given model estimator, or many models with a given data sample and track everything in **MLRun**.  Research, development, and deployment, all on one page, running under multiple configurations, limited only by the compute resources at our disposal.\n",
    "\n",
    "\n",
    "#### **notebook take-aways**\n",
    "* write and test reusable and replaceable **[MLRun](https://github.com/mlrun)** components in a notebook, file or github repository\n",
    "* store and load models\n",
    "* run the components as a **[KubeFlow](https://www.kubeflow.org/)** pipeline\n",
    "\n",
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[nuclio code section](#nuclio-code-section)**<br>\n",
    "    - [nuclio's ignore](#ignore)<br>\n",
    "    - [function dependencies](#function-dependencies)<br>\n",
    "\n",
    "**[components](#components)**<br>\n",
    "    - [supporting functions](#imports)<br>\n",
    "    - [data simulation](#data_generator)<br>\n",
    "    - [feature engineering](#feateng)<br>\n",
    "    - [a classifier](#classifier)<br>\n",
    "    - [save and load pipeline model](#save-load)<br>\n",
    "    - [training and validation](#train)<br>\n",
    "**[local tests](#local-testing)**<br>\n",
    "**[remote tests](#remote)**<br>\n",
    "**[compose pipeline](#compose)**<br>\n",
    "**[run](#run)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio-code-section\"></a>\n",
    "# **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ignore'></a>\n",
    "### _nuclio's **ignore** notation_\n",
    "\n",
    "You'll write all the code that gets packaged for execution between the tags ```# nuclio: ignore```, meaning ignore all the code here and above, and ```# nuclio: end-code```, meaning ignore everything after this annotation.  The **[docs](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** also suggest another approach: we can use ```# nuclio: start``` at the first relevant code cell instead of marking all the cells above with ```# nuclio: ignore```.\n",
    "\n",
    "See the **[nuclio-jupyter](https://github.com/nuclio/nuclio-jupyter)** repo for further information on these and many other **[nuclio magic commands](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** that make it easy to transform a Jupyter notebook environment into a platform for developing production-quality, machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lines _**should be in the same cell**_ and mark the start of your mchine learning coding section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"function-dependencies\"></a>\n",
    "### _function dependencies_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installs made in the section **[Setup](#Setup)** covered the Jupyter environment within which this notebook runs.  However, we need to ensure that all the dependencies our nuclio function relies upon (such as ```matplotlib```, ```sklearn```, ```lightgbm```), will be available when that code is wrapped up into a nuclio function _**on some presently unknown runtime**_.   Within the nuclio code section we can ensure these dependencies get built into the function with the ```%nuclio cmd``` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd\n",
    "rm /conda/lib/python3.6/site-packages/seaborn* -rf\n",
    "pip install -U -q seaborn\n",
    "pip install -U -q matplotlib\n",
    "pip install -U -q tensorflow==2.0.0b1\n",
    "pip install -U -q scikit-learn\n",
    "pip install -U -q pandas \n",
    "pip install -U -q numpy==1.17.4\n",
    "pip install -U -q git+https://github.com/yjb-ds/functions-demo.git\n",
    "    \n",
    "pip uninstall -y mlrun\n",
    "pip install -U -q git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\"ll use a standard base image here, however the build step can be shortened by preparing images with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"support\"></a>\n",
    "### _imports_\n",
    "\n",
    "Some of the functionality is provided in custom components within the ```functions``` package (found at the github repo **[function-demos](https://github.com/yjb-ds/functions-demo)**):<br>\n",
    "\n",
    "- **[datasets](functions/datasets.py)**:&emsp;generate simulation data\n",
    "- **[files](functions/file_fs.py)**:&emsp;&emsp;&emsp;save and load _remote_ files\n",
    "- **[models](function/model_fs.py)**:&nbsp; &emsp;save, load, and instantiate models\n",
    "- **[plots](functions/plot_fs.py)**:&emsp;  &emsp; sundry plotting functions\n",
    "- **[tables](functions/tables.py)**:&emsp; &nbsp; &nbsp;logging and retrieving table artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from pickle import dump, load\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.datasets import create_binary_classification\n",
    "from functions.models import (build_fn,\n",
    "                              FeaturesEngineer, \n",
    "                              KerasClassifier,\n",
    "                              class_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Union, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='paths'></a>\n",
    "### _paths and parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = '/User/mlrun/simdata'\n",
    "\n",
    "# data simulation and ml training parameter\n",
    "BATCH_SIZE = 1_024\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS= 3\n",
    "N_SAMPLES = 1_000_000\n",
    "M_FEATURES = 20\n",
    "CLASS_BALANCE = 0.5\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"components\" ></a>\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **components**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_generator'></a>\n",
    "## **data generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    context: MLClientCtx,\n",
    "    samples: int,\n",
    "    features: int,\n",
    "    features_hdr: Optional[List[str]],\n",
    "    neg_weight: float,\n",
    "    target_path: str,\n",
    "    key: str\n",
    ") -> None:\n",
    "    \"\"\"Generate raw data for this pipeline\n",
    "    \n",
    "    This component will be the entry point of the pipeline.\n",
    "    \n",
    "    In this demonstration our component is a simple wrapper for scikit learn's \n",
    "    `make_classification`, a convenient utility enabling us to build\n",
    "    and test a pipeline from start to finish with a clean and \n",
    "    predictable dataset. By fiddling with neg_weight, we can also take a \n",
    "    quick look at the effect of class balance on our model before exposing it\n",
    "    to the kind of data we find in the real world.\n",
    "    \n",
    "    :param context:       function context\n",
    "    :param samples:       number of samples (rows) to generate\n",
    "    :param features:      number of features (cols)\n",
    "    :param features_hdr:  (optional) header for the features array\n",
    "    :param neg_weights:   fraction of negative samples\n",
    "    :param target_path:   destination for data including file name\n",
    "    :param key:           context key of data\n",
    "    \"\"\"\n",
    "    if features_hdr:\n",
    "        assert len(features_hdr)==m_features, f\"features header dimension mismatch for {name}\"\n",
    "    data = create_binary_classification(\n",
    "                context, n_samples=samples, m_features=features,\n",
    "                features_hdr=features_hdr,  weight=neg_weight, \n",
    "                target_path=target_path, key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feateng'></a>\n",
    "## **feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class implements the scikit-learn transformer API, enabling it to fit into an sklearn `Pipeline` as a step.<br>\n",
    "\n",
    "For code please see the custom sklearn transformer `FeaturesEngineer` in **[models.py](functions/models.py)**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifier\"></a>\n",
    "## **classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method generates a small keras Sequential model with 2 layers which gets wrapped in a `KerasClassifier` class. The latter provides it with a convenient sklearn interface for use in **[sklearn Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn-pipeline-pipeline)**. The list of metrics collected during training can also be found in the same module as `METRICS` and includes accuracy, precision, recall, auc and a confusion matrix.<br>\n",
    "\n",
    "For code please see `KerasClassifier` and `build_fn` in **[models.py](functions/models.py)**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train'></a>\n",
    "## **training and validation**\n",
    "\n",
    "In this notebook demonstration we follow standard practice by wrapping the training/validation and test steps into the same method.\n",
    "\n",
    "**exercise / todos**\n",
    "\n",
    "To complete the demonstration, instead of hard-coding the `train_test_split` method, add a splitter class into the pipeline, like a cross-validator. \n",
    "\n",
    "The model encoder/decoder could also be input as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    context: MLClientCtx,\n",
    "    dataset: DataItem,\n",
    "    engineer_cls: str,\n",
    "    scaler_cls: str,\n",
    "    classifier_cls: str,\n",
    "    target_path: str,\n",
    "    model_key: str = '',\n",
    "    test_data_key: str = '',\n",
    "    metrics_key: str = '',\n",
    "    test_size: float = 0.1,\n",
    "    valid_size: float = 0.3,\n",
    "    batch_size: int = 1024,\n",
    "    epochs: int = 5,\n",
    "    verbose: bool = True,\n",
    "    random_state: int = 1,\n",
    "    ) -> None:\n",
    "    \"\"\"Train, validate, test and save a classifier model pipeline.\n",
    "    \n",
    "    Here we split the data, instantiate our pipeline and its models, and proceed\n",
    "    to training and validation.\n",
    "    \n",
    "    The target_path defines the base folder where artifacts will be stored.  Since we\n",
    "    intend to save both the model (and its components), the test set and its predictions,\n",
    "    and the history of metric estimates we provide three keys.\n",
    "    \n",
    "    :param context:             function context\n",
    "    :param dataset:             cleaned input dataset\n",
    "    :param engineer_cls:        feature engineering class\n",
    "    :param scaler_cls:          scaler class\n",
    "    :param classifier_cls:      classifier class    \n",
    "    :param target_path:         destination (folder) for artifact files\n",
    "    :param model_key:           model key in the artifact store\n",
    "    :param test_data_key:       test set and predictions key in the artifact store\n",
    "    :param metrics_key:         metrics key in the artifact store\n",
    "    :param test_size:           (0.1) test set size as fraction\n",
    "    :param valid_size:          (0.3) validation set size as fraction\n",
    "    :param batch_size:          (1024) network feed batch size\n",
    "    :param epochs:              (5) training epochs\n",
    "    :param verbose:             (default True) Show metrics for \n",
    "                                training/validation steps\n",
    "        \n",
    "    Also included for demonstration are a randomly selected sample\n",
    "    of training parameters:\n",
    "    :param learning_rate: Step size at each iteration, constant.\n",
    "    \"\"\"\n",
    "    raw = pd.read_parquet(io.BytesIO(dataset.get()), engine='pyarrow')\n",
    "\n",
    "    train, test = train_test_split(raw, test_size=test_size)\n",
    "    train, valid = train_test_split(train, test_size=valid_size)\n",
    "    \n",
    "    y_train = train.pop('labels')\n",
    "    y_valid = valid.pop('labels')\n",
    "    y_test = test.pop('labels')\n",
    "\n",
    "    # instantiate features engineer, scaler and classifier\n",
    "    Engineer = class_instance(engineer_cls)\n",
    "    Scaler = class_instance(scaler_cls)\n",
    "    Classifier = class_instance(classifier_cls)\n",
    "\n",
    "    pipe = Pipeline(steps=[('engineer', Engineer()),\n",
    "                           ('scaler', Scaler()),\n",
    "                           ('classifier', KerasClassifier(build_fn=build_fn, input_size=20))])\n",
    "    pipe.fit(train, y_train,\n",
    "             classifier__epochs=epochs, \n",
    "             classifier__batch_size=batch_size,\n",
    "             classifier__validation_split=0.25) # fudge\n",
    "\n",
    "    y_pred = pipe.predict(test)                          \n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    context.log_result(\"accuracy\", float(acc))\n",
    "    \n",
    "    # keras metrics history is a table\n",
    "    metrics = pd.DataFrame(pipe.named_steps.classifier.model.history.history)\n",
    "    \n",
    "    # run plotting routines\n",
    "    _plot_validation(metrics.loss, \n",
    "                     metrics.valid_loss, \n",
    "                     target_path=target_path, \n",
    "                     key='training-validation-metrics')\n",
    "    _plot_roc(y_test, y_pred, target_path=target_path, key='roc-curve')\n",
    "    _plot_confusion_matrix(y_test, y_pred, target_path=target_path, key='confusion-matrix')\n",
    "    \n",
    "    \n",
    "    modelpath = os.path.join(target_path, model_key + '.pkl')\n",
    "    dump(pipe, open(modelpath, 'wb'))\n",
    "    context.log_artifact(model_key, target_path=modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _end of nuclio function definition_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"local-testing\" ></a>\n",
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **testing your code locally**\n",
    "\n",
    "The function can be run locally and debugged/tested before deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import (mlconf,\n",
    "                   code_to_function,\n",
    "                   new_function,\n",
    "                   NewTask,\n",
    "                   new_model_server,\n",
    "                   mount_v3io)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set MLRun's DB path.  MLRun wil generate and store all of its tracking and metadata to the `MLRUN_DBATH` environment variable.  We have set a `TARGET_PATH` earlier in this notebook in the above section **[paths and parameters](#paths)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = new_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_run = workflow.run(\n",
    "    name='data generator',\n",
    "    handler=data_generator,\n",
    "    params={\n",
    "        'samples':      N_SAMPLES,\n",
    "        'features':     M_FEATURES,\n",
    "        'neg_weight':   CLASS_BALANCE, # this is a balanced dataset\n",
    "        'target_path':  TARGET_PATH,\n",
    "        'key':          'simdata'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run = workflow.run(\n",
    "    name='train, validate and store model',\n",
    "    handler=train,\n",
    "    inputs={\n",
    "        'dataset': datagen_run.outputs['simdata']},\n",
    "    params={\n",
    "        'scaler_cls':     'sklearn.preprocessing.data.StandardScaler',\n",
    "        'engineer_cls':   'functions.models.FeaturesEngineer',\n",
    "        'classifier_cls': 'functions.models.KerasClassifier',\n",
    "        'target_path':     TARGET_PATH,\n",
    "        'model_key':       'model',\n",
    "        'test_data_key':   'test_data',\n",
    "        'metrics_key':     'metrics',\n",
    "        'batch_size':      BATCH_SIZE,\n",
    "        'epochs':          25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history = workflow.run(\n",
    "    name='training history',\n",
    "    handler=plot_validation,\n",
    "    inputs={'metrics': train_run.outputs['metrics']},\n",
    "    params={\n",
    "        'fmt': 'png',\n",
    "        'target_path': TARGET_PATH,\n",
    "        'key' : 'training',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history = workflow.run(\n",
    "    name='confusion matrix',\n",
    "    handler=plot_confusion_matrix,\n",
    "    inputs={'test_data': train_run.outputs['test_data']},\n",
    "    params={'labels': [0, 1],\n",
    "            'target_path': TARGET_PATH, \n",
    "            'key': 'confusion_matrix'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"image\"></a>\n",
    "#### _Create a deployment image_\n",
    "\n",
    "Once debugged you can create a reusable image, and then deploy it for testing. In the following line we are converting the code block between the ```#nuclio: ignore``` and ```#nuclio: end-code``` to be run as a KubeJob. _**It is important to ensure that this function has been `deploy`ed at least once, and that you have access to it.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkeras_job = code_to_function(name='tfkeras_job',\n",
    "                               runtime=\"job\").apply(mount_v3io())\n",
    "\n",
    "# set this to True so that updates to our git package are reflected in the built image,\n",
    "# but please note however that this may lengthen image build times:\n",
    "# tfkeras_job.spec.no_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkeras_job.deploy()\n",
    "# other options:\n",
    "# ignore if exists\n",
    "# save and/or export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfkeras_job.with_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"remote\"></a>\n",
    "# **test your code remotely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = NewTask()\n",
    "\n",
    "task.with_params(samples=N_SAMPLES,\n",
    "                 features=M_FEATURES,\n",
    "                 neg_weight=CLASS_BALANCE,\n",
    "                 target_path=TARGET_PATH,\n",
    "                 key='simdata')\n",
    "\n",
    "nrun = tfkeras_job.run(task, \n",
    "                       handler='data_generator', \n",
    "                       out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.with_input('dataset', nrun.outputs['simdata'])\n",
    "\n",
    "task.with_params(scaler_cls='sklearn.preprocessing.data.StandardScaler',\n",
    "                 engineer_cls='functions.models.FeaturesEngineer',\n",
    "                 classifier_cls='functions.models.KerasClassifier',\n",
    "                 target_path=TARGET_PATH,\n",
    "                 model_key='model',\n",
    "                 test_data_key='test_data',\n",
    "                 metrics_key='metrics',\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 epochs=10)\n",
    "\n",
    "nrun2 = tfkeras_job.run(task, handler='train', out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.with_input('metrics', nrun2.outputs['metrics'])\n",
    "\n",
    "task.with_params(fmt='png', target_path=TARGET_PATH, key='training')\n",
    "\n",
    "nrun3 = tfkeras_job.run(task, handler='plot_validation', out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.with_input('test_data', nrun2.outputs['test_data'])\n",
    "\n",
    "task.with_params(labels=[0, 1], fmt='png', target_path=TARGET_PATH, key='confusion_matrix')\n",
    "\n",
    "nrun4 = tfkeras_job.run(task, handler='plot_confusion_matrix', out_path=TARGET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compose\"></a>\n",
    "# **Create a KubeFlow Pipeline from our functions**\n",
    "\n",
    "Our pipeline will consist of two steps, ```data_generator``` and ```train```.\n",
    "\n",
    "For complete details on KubeFlow Pipelines please refer to the following docs:\n",
    "1. **[KubeFlow pipelines](https://www.kubeflow.org/docs/pipelines/)**.\n",
    "2. **[kfp.dsl Python package](https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#module-kfp.dsl)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, the model server file name in the ```new_model_server``` function call below should identical in every respect to the name of the model server notebook (here, **[model_server.ipynb](#model-server.ipynb)**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srvfn = new_model_server(\"tfkeras\",  \n",
    "                         model_class=\"MyKerasClassifier\",   \n",
    "                         filename=\"model_server.ipynb\")\n",
    "srvfn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Sklearn and KubeFlow\",\n",
    "    description=\"Shows how to use mlrun/kfp.\"\n",
    ")\n",
    "def tfkeras_pipeline(\n",
    "    neg_weight = [0.5, 0.1],\n",
    "):\n",
    "\n",
    "    datagen = tfkeras_job.as_step(\n",
    "        name='data generator',\n",
    "        handler='data_generator',\n",
    "        out_path=TARGET_PATH, \n",
    "        params={        \n",
    "            'samples':         N_SAMPLES,\n",
    "            'features':        M_FEATURES,\n",
    "            'neg_weight':      CLASS_BALANCE,\n",
    "            'target_path':     TARGET_PATH,\n",
    "            'key':            'simdata'},\n",
    "        outputs=['simdata']).apply(mount_v3io())\n",
    "    \n",
    "    train = tfkeras_job.as_step(\n",
    "        name='sklearn pipe train',\n",
    "        handler='train',\n",
    "        out_path=TARGET_PATH, \n",
    "        inputs={'dataset': datagen.outputs['simdata']},\n",
    "        outputs=['model', 'test_data', 'metrics'],\n",
    "        params={\n",
    "            'scaler_cls':     'sklearn.preprocessing.data.StandardScaler',\n",
    "            'engineer_cls':   'functions.models.FeaturesEngineer',\n",
    "            'classifier_cls': 'functions.models.classifier',\n",
    "            'target_path':     TARGET_PATH,\n",
    "            'model_key':      'model',\n",
    "            'test_data_key':  'test_data',\n",
    "            'metrics_key':    'metrics',\n",
    "            'batch_size':      BATCH_SIZE,\n",
    "            'epochs':          10}).apply(mount_v3io())\n",
    "\n",
    "    plot_valid = tfkeras_job.as_step(\n",
    "        name='plot training validation accuracy',\n",
    "        handler='plot_validation',\n",
    "        out_path=TARGET_PATH, \n",
    "        inputs={'metrics': train.outputs['metrics']},\n",
    "        params={\n",
    "            'target_path':     TARGET_PATH,\n",
    "            'key':             'history',\n",
    "            'fmt':             'png'}).apply(mount_v3io())\n",
    "\n",
    "    plot_confusion = tfkeras_job.as_step(\n",
    "        name='plot confusion matrix',\n",
    "        handler='plot_confusion_matrix',\n",
    "        out_path=TARGET_PATH, \n",
    "        inputs={'test_data': train.outputs['test_data']},\n",
    "        outputs=['model'],\n",
    "        params={\n",
    "            'labels':          [0, 1], \n",
    "            'target_path':     TARGET_PATH,\n",
    "            'key':             'confusion',\n",
    "            'fmt':             'png'}).apply(mount_v3io())\n",
    "\n",
    "    # define a nuclio-serving function, generated from a notebook file\n",
    "    srvfn.deploy_step(project=\"github-demos\", \n",
    "                      models={\"tfkeras_pickle\": train.outputs[\"model\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compile the pipeline\"></a>\n",
    "### _compile the pipeline_\n",
    "\n",
    "We can compile our KubeFlow pipeline and produce a yaml description of the pipeline worflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(TARGET_PATH, exist_ok=True)\n",
    "kfp.compiler.Compiler().compile(tfkeras_pipeline, TARGET_PATH+\"/mlrunpipe.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace=\"default-tenant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following line will run the pipeline as a job::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\n",
    "    'neg_weight' : [0.5, 0.1]    \n",
    "}\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    tfkeras_pipeline, \n",
    "    arguments, \n",
    "    run_name=\"tfkeras\",\n",
    "    experiment_name=\"tfkeras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlrun clean"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
