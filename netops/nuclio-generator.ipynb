{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclio - Generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "# Utils\n",
    "pip install pyarrow\n",
    "pip install pyyaml --upgrade\n",
    "pip install pandas\n",
    "pip install pytimeparse\n",
    "\n",
    "# Igz DB\n",
    "pip install v3io_frames --upgrade\n",
    "\n",
    "# Function\n",
    "pip install -i https://test.pypi.org/simple/ v3io-generator\n",
    "pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# MLRun\n",
    "from mlrun import get_or_create_ctx\n",
    "\n",
    "# DB Connection\n",
    "import v3io_frames as v3f\n",
    "\n",
    "# Data generator\n",
    "from v3io_generator import metrics_generator, deployment_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_deployment():\n",
    "    context.logger.info('Creating deployment')\n",
    "    # Create meta-data factory\n",
    "    dep_gen = deployment_generator.deployment_generator()\n",
    "    faker=dep_gen.get_faker()\n",
    "\n",
    "    # Design meta-data\n",
    "    dep_gen.add_level(name='company',number=2,level_type=faker.company)\n",
    "    dep_gen.add_level('data_center',number=2,level_type=faker.street_name)\n",
    "    dep_gen.add_level('device',number=2,level_type=faker.msisdn)\n",
    "\n",
    "    # Create meta-data\n",
    "    deployment_df = dep_gen.generate_deployment()\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_deployment_exist(path):\n",
    "    # Checking shared path for the devices table\n",
    "    return os.path.exists(f'/v3io/bigdata/{path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_deployment_from_kv(client, path):\n",
    "    context.logger.info(f'Retrieving deployment from {path}')\n",
    "    # Read the devices table from our KV store\n",
    "    deployment_df = client.read(backend='kv', table=path)\n",
    "    \n",
    "    # Reset index to column\n",
    "    deployment_df.index.name = 'device'\n",
    "    deployment_df = deployment_df.reset_index()\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_deployment_to_kv(path, df, client=None):\n",
    "    context.logger.info(f'Saving deployment to {path}')\n",
    "    # Save deployment to our KV store\n",
    "    client.write(backend='kv', table=path ,dfs=df, index_cols=['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_deployment(path, client=None):\n",
    "    deployment_df = None\n",
    "    if client and _is_deployment_exist(path):\n",
    "        # Get deployment from KV\n",
    "        deployment_df = _get_deployment_from_kv(client, path)\n",
    "    else:\n",
    "        # Create deployment\n",
    "        deployment_df = _create_deployment()\n",
    "        \n",
    "        context.logger.info(deployment_df)\n",
    "        if client:\n",
    "            _save_deployment_to_kv(path, deployment_df, client)\n",
    "\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_indexes(df):\n",
    "    df = df.set_index(['time', 'company', 'data_center', 'device'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_tsdb(client, metrics: pd.DataFrame, metrics_table):\n",
    "    client.write('tsdb', metrics_table, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_parquet(metrics, metrics_table):\n",
    "#     df = pd.concat(itertools.chain(metrics))\n",
    "    \n",
    "    # Need to fix timestamps from ns to ms if we write to parquet\n",
    "    df = metrics.reset_index()\n",
    "    df['time'] = df.loc[:, 'time'].astype('datetime64[ms]')\n",
    "    \n",
    "    # Fix indexes\n",
    "    df = set_indexes(df)\n",
    "    \n",
    "    # Save parquet\n",
    "    first_timestamp = df.index[0][0].strftime('%Y%m%dT%H%M%S')\n",
    "    last_timestamp = df.index[-1][0].strftime('%Y%m%dT%H%M%S')\n",
    "    filename = first_timestamp + '-' + last_timestamp + '.parquet'\n",
    "    filedir = os.path.join(os.getcwd(), metrics_table)\n",
    "    filepath = os.path.join(filedir, filename)\n",
    "    os.makedirs(filedir, exist_ok=True)\n",
    "    with open(filepath, 'wb+') as f:\n",
    "        df.to_parquet(f)\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3c = v3f.Client(address='framesd:8081', container='bigdata')\n",
    "\n",
    "def generator(context,\n",
    "              metrics_configuration_file,\n",
    "              initial_timestamp,\n",
    "              use_tsdb,\n",
    "              metrics_table,\n",
    "              deployment_table,\n",
    "              secs_to_generate = 180000):\n",
    "    \n",
    "    # load MLRUN runtime context (will be set by the runtime framework e.g. KubeFlow)\n",
    "    context.logger.info('Loading parameters')\n",
    "    metrics_configuration = yaml.safe_load(metrics_configuration_file.get())\n",
    "\n",
    "    # Set V3IO Connection if needed\n",
    "    client = None\n",
    "    if use_tsdb:\n",
    "        client = v3f.Client(address='framesd:8081', container='bigdata')\n",
    "        client.create('tsdb', metrics_table, attrs={'rate': '1/s'}, if_exists=True)\n",
    "    \n",
    "    # Generate or create deployment\n",
    "    deployment_df = get_or_create_deployment(deployment_table, client)\n",
    "    context.logger.info(f'Deployment:\\n{deployment_df}')\n",
    "\n",
    "#     ## Set base initial values \n",
    "    deployment_df['cpu_utilization'] = 70\n",
    "    deployment_df['latency'] = 0\n",
    "    deployment_df['packet_loss'] = 0\n",
    "    deployment_df['throughput'] = 290\n",
    "\n",
    "    context.logger.info(f'Metrics Configuration:\\n{metrics_configuration}')\n",
    "    \n",
    "#     # Create metrics generator\n",
    "    start_time = datetime.datetime.fromtimestamp(initial_timestamp)\n",
    "    end_time = (datetime.datetime.fromtimestamp(initial_timestamp)+datetime.timedelta(seconds=secs_to_generate))\n",
    "    context.logger.info(f'Generating data from {start_time} to {end_time}')\n",
    "    \n",
    "    met_gen = metrics_generator.Generator_df(metrics_configuration, \n",
    "                                             user_hierarchy=deployment_df, \n",
    "                                             initial_timestamp=start_time)\n",
    "    \n",
    "    # Create metrics generator based on YAML configuration and deployment\n",
    "    metrics = met_gen.generate_range(start_time=start_time,\n",
    "                                     end_time=end_time,\n",
    "                                     as_df=True,\n",
    "                                     as_iterator=True)\n",
    "    \n",
    "    metrics = pd.concat(itertools.chain(metrics))\n",
    "    metrics = metrics.reset_index()\n",
    "    metrics = metrics.rename(columns={'timestamp': 'time'})\n",
    "    context.logger.info(f'Generated metrics:\\nSample: {metrics.head(1)}')\n",
    "    \n",
    "    # Save Generated metrics\n",
    "    if use_tsdb:\n",
    "        # Prepare dataframe for TSDB\n",
    "        metrics = set_indexes(metrics)\n",
    "        \n",
    "        # Save to TSDB\n",
    "        client.write('tsdb', metrics_table, metrics)\n",
    "        context.logger.info(f'Saved data to TSDB: {metrics_table}')\n",
    "    else:\n",
    "        # Prepare dataframe for parquet\n",
    "        metrics['time'] = metrics.loc[:, 'time'].astype('datetime64[ms]')\n",
    "        metrics = set_indexes(metrics)\n",
    "        \n",
    "        # Prepare filename\n",
    "        first_timestamp = metrics.index[0][0].strftime('%Y%m%dT%H%M%S')\n",
    "        last_timestamp = metrics.index[-1][0].strftime('%Y%m%dT%H%M%S')\n",
    "        filename = first_timestamp + '-' + last_timestamp + '.parquet'\n",
    "        filedir = os.path.join(os.getcwd(), metrics_table)\n",
    "        filepath = os.path.join(filedir, filename)\n",
    "        \n",
    "        # Save to Parquet\n",
    "        os.makedirs(filedir, exist_ok=True)\n",
    "        with open(filepath, 'wb+') as f:\n",
    "            metrics.to_parquet(f)\n",
    "            \n",
    "        context.log_artifact('metrics', src_path=filepath, target_path=os.path.join(metrics_table, filename), upload=True)\n",
    "        context.logger.info(f'Saved data to Parquet: {filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, mount_v3io, NewTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2019-11-21 14:07:13,661 starting run generator uid=b7423c77fff04f5590575424e48b7b8e  -> \n",
      "Python> 2019-11-21 14:07:13,766 [info] Creating deployment\n",
      "Python> 2019-11-21 14:07:15,960 [info]                     company      data_center         device\n",
      "0  Lee__Long_and_Mcdonald    Freeman_Freeway  9005962208179\n",
      "1  Lee__Long_and_Mcdonald    Freeman_Freeway  0067276276197\n",
      "2  Lee__Long_and_Mcdonald    Nicole_Parks     8720773551943\n",
      "3  Lee__Long_and_Mcdonald    Nicole_Parks     1805119819383\n",
      "4  Cabrera__Potts_and_Woods  Nicholas_Creek   4421711016950\n",
      "5  Cabrera__Potts_and_Woods  Nicholas_Creek   4722194065084\n",
      "6  Cabrera__Potts_and_Woods  Valerie_Camp     0144265178195\n",
      "7  Cabrera__Potts_and_Woods  Valerie_Camp     6749132011465\n",
      "[mlrun] 2019-11-21 14:07:13,751 Loading parameters\n",
      "[mlrun] 2019-11-21 14:07:15,972 Deployment:\n",
      "                    company      data_center         device\n",
      "0  Lee__Long_and_Mcdonald    Freeman_Freeway  9005962208179\n",
      "1  Lee__Long_and_Mcdonald    Freeman_Freeway  0067276276197\n",
      "2  Lee__Long_and_Mcdonald    Nicole_Parks     8720773551943\n",
      "3  Lee__Long_and_Mcdonald    Nicole_Parks     1805119819383\n",
      "4  Cabrera__Potts_and_Woods  Nicholas_Creek   4421711016950\n",
      "5  Cabrera__Potts_and_Woods  Nicholas_Creek   4722194065084\n",
      "6  Cabrera__Potts_and_Woods  Valerie_Camp     0144265178195\n",
      "7  Cabrera__Potts_and_Woods  Valerie_Camp     6749132011465\n",
      "[mlrun] 2019-11-21 14:07:15,975 Metrics Configuration:\n",
      "{'errors': {'length_in_ticks': 50, 'rate_in_ticks': 150}, 'metrics': {'cpu_utilization': {'accuracy': 2, 'distribution': 'normal', 'distribution_params': {'mu': 70, 'noise': 0, 'sigma': 10}, 'is_threshold_below': True, 'past_based_value': False, 'produce_max': False, 'produce_min': False, 'validation': {'distribution': {'max': 1, 'min': -1, 'validate': False}, 'metric': {'max': 100, 'min': 0, 'validate': True}}}, 'latency': {'accuracy': 2, 'distribution': 'normal', 'distribution_params': {'mu': 0, 'noise': 0, 'sigma': 5}, 'is_threshold_below': True, 'past_based_value': False, 'produce_max': False, 'produce_min': False, 'validation': {'distribution': {'max': 1, 'min': -1, 'validate': False}, 'metric': {'max': 100, 'min': 0, 'validate': True}}}, 'packet_loss': {'accuracy': 0, 'distribution': 'normal', 'distribution_params': {'mu': 0, 'noise': 0, 'sigma': 2}, 'is_threshold_below': True, 'past_based_value': False, 'produce_max': False, 'produce_min': False, 'validation': {'distribution': {'max': 1, 'min': -1, 'validate': False}, 'metric': {'max': 50, 'min': 0, 'validate': True}}}, 'throughput': {'accuracy': 2, 'distribution': 'normal', 'distribution_params': {'mu': 250, 'noise': 0, 'sigma': 20}, 'is_threshold_below': False, 'past_based_value': False, 'produce_max': False, 'produce_min': False, 'validation': {'distribution': {'max': 1, 'min': -1, 'validate': False}, 'metric': {'max': 300, 'min': 0, 'validate': True}}}}, 'timestamps': {'interval': '5s', 'stochastic_interval': True}}\n",
      "[mlrun] 2019-11-21 14:07:15,975 Generating data from 2019-11-20 14:07:13.660885 to 2019-11-20 14:07:23.660885\n",
      "[mlrun] 2019-11-21 14:07:16,181 Generated metrics:\n",
      "Sample:                         time      data_center                 company  \\\n",
      "0 2019-11-20 14:07:18.660885  Freeman_Freeway  Lee__Long_and_Mcdonald   \n",
      "\n",
      "          device  cpu_utilization  cpu_utilization_is_error   latency  \\\n",
      "0  9005962208179  79.387389        False                     3.214853   \n",
      "\n",
      "   latency_is_error  packet_loss  packet_loss_is_error  throughput  \\\n",
      "0  False             0.0          False                 249.77851    \n",
      "\n",
      "   throughput_is_error  is_error  \n",
      "0  False                False     \n",
      "[mlrun] 2019-11-21 14:07:16,219 Saved data to Parquet: /User/mlrun-demos/demos/netops/netops_metrics/20191120T140718-20191120T140728.parquet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"b7423c77fff04f5590575424e48b7b8e\">...8b7b8e</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 21 14:07:13</td>\n",
       "      <td>completed</td>\n",
       "      <td>generator</td>\n",
       "      <td><div class=\"dictlist\">repo=http://github.com/mlrun/demos</div><div class=\"dictlist\">commit=a6a1680459beaaec4b527712ff0dd15c1109f917</div><div class=\"dictlist\">kind=handler</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">host=jupyter-h4pye88pz3-itkjk-6bbcdb955c-j8xtr</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result08ebd70c\" title=\"/files/mlrun-demos/demos/netops/configurations/metrics_configuration.yaml\">metrics_configuration_file</div></td>\n",
       "      <td><div class=\"dictlist\">use_tsdb=False</div><div class=\"dictlist\">deployment_table=netops_deployment</div><div class=\"dictlist\">metrics_table=netops_metrics</div><div class=\"dictlist\">initial_timestamp=1574258833.660885</div><div class=\"dictlist\">secs_to_generate=10</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"/User/mlrun-db/data/netops_metrics/20191120T140718-20191120T140728.parquet\">metrics</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result08ebd70c-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result08ebd70c-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result08ebd70c\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result08ebd70c-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type result.show() to see detailed results/progress or use CLI:\n",
      "!mlrun get run --uid b7423c77fff04f5590575424e48b7b8e \n",
      "[mlrun] 2019-11-21 14:07:16,239 run executed, status=completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.model.RunObject at 0x7f1f49948048>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "params = {\n",
    "    'use_tsdb': False,\n",
    "    'deployment_table': 'netops_deployment',\n",
    "    'metrics_table': 'netops_metrics',\n",
    "    'initial_timestamp': (datetime.datetime.now()-datetime.timedelta(days=1)).timestamp(),\n",
    "    'secs_to_generate': 10\n",
    "}\n",
    "inputs = {\n",
    "    'metrics_configuration_file': os.path.join(os.getcwd(), \n",
    "                                              'configurations', \n",
    "                                              'metrics_configuration.yaml')\n",
    "}\n",
    "\n",
    "fn = new_function(runtime='', interactive=True)\n",
    "task = NewTask(handler=generator, \n",
    "               params=params, \n",
    "               inputs=inputs,\n",
    "               out_path='/User/mlrun-db/data/')\n",
    "fn.run(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
