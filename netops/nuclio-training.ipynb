{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclio - Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.triggers.retrain.kind to 'cron'\n",
      "%nuclio: setting spec.triggers.retrain.attributes.interval to '1h'\n",
      "%nuclio: setting spec.build.baseImage to 'daskdev/dask'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config\n",
    "\n",
    "# Trigger\n",
    "spec.triggers.retrain.kind = \"cron\"\n",
    "spec.triggers.retrain.attributes.interval = \"1h\"\n",
    "\n",
    "# Base image\n",
    "spec.build.baseImage = \"daskdev/dask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mounting volume path /User as ~/\n"
     ]
    }
   ],
   "source": [
    "%nuclio mount /User ~/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "# apt-get update && apt-get install -y libaio1\n",
    "# apt-get install libgomp1 \n",
    "\n",
    "############\n",
    "# installs #\n",
    "############\n",
    "\n",
    "# Igz DB\n",
    "pip install v3io_frames\n",
    "\n",
    "# Utils\n",
    "pip install 'fsspec>=0.3.3'\n",
    "pip install pyarrow\n",
    "\n",
    "# Function\n",
    "pip install dask-ml\n",
    "pip install dask-xgboost --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Config\n",
    "%nuclio env %v3io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "\n",
    "# DB Connection\n",
    "import v3io_frames as v3f\n",
    "\n",
    "# Parallelization\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Function\n",
    "import dask_xgboost as dxgb\n",
    "import dask_ml.model_selection as dcv\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_from_tsdb(context, df):\n",
    "    df.index.names = ['timestamp', 'company', 'data_center', 'device']\n",
    "    df = df.reset_index()\n",
    "    df = dd.from_pandas(df, npartitions=context.shards)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsdb(context, features_table, train_on_last, dask_shards):\n",
    "    df = context.v3f.read(backend='tsdb', query=f'select * from {features_table}',\n",
    "                          start=f'now-{train_on_last}', end='now', multi_index=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[sorted(df.columns)]\n",
    "    df = dd.from_pandas(df, npartitions=dask_shards)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_parquet(context, features_table, train_on_last, dask_shards):\n",
    "    # Get parquet files\n",
    "    mpath = [os.path.join(features_table, file) for file in os.listdir(features_table) if os.path.isdir(os.path.join(features_table, file))]\n",
    "    \n",
    "    # Get latest filename\n",
    "    latest = max(mpath, key=os.path.getmtime)\n",
    "    context.logger.info(f'Reading data from: {latest}')\n",
    "    \n",
    "    # Load parquet to dask\n",
    "    df = dd.read_parquet(latest, infer_divisions=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets_from_data(context, \n",
    "                                  df, \n",
    "                                  metrics, \n",
    "                                  labels, \n",
    "                                  train_size):\n",
    "    X = df.loc[:, metrics]\n",
    "    y = df.loc[:, labels]\n",
    "    X_train, X_test, y_train, y_test = dcv.train_test_split(X, y, train_size=train_size, test_size=1-train_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_dask_xgboost(context, \n",
    "            save_to_tsdb=0,\n",
    "            labels=[],\n",
    "            metrics=[],\n",
    "            features_table='/v3io/bigdata/netops_features_parquet',\n",
    "            model_filepath='/v3io/bigdata/netops/models/netops.model',\n",
    "            train_on_last='7d',\n",
    "            train_size=0.7,\n",
    "            dask_shards=4):\n",
    "    \n",
    "    # Setup context   \n",
    "    if save_to_tsdb:\n",
    "        # Create V3IO connection\n",
    "        v3io_client = v3f.Client(address='framesd:8081', \n",
    "                                 container='bigdata')\n",
    "        setattr(context, 'v3f', v3io_client)\n",
    "        \n",
    "        # Create features table if neede\n",
    "        context.v3f.create('tsdb', \n",
    "                           features_table, \n",
    "                           attrs={'rate': '1/s'}, \n",
    "                           if_exists=1)\n",
    "    \n",
    "        # Set TSDB reading function\n",
    "        setattr(context, 'read', get_data_tsdb)\n",
    "    \n",
    "    # Save to Parquet\n",
    "    else:\n",
    "         # Create saving directory if needed\n",
    "        filepath = os.path.join(features_table)\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "            \n",
    "        # Set Parquet reading function\n",
    "        setattr(context, 'read', get_data_parquet)\n",
    "        \n",
    "    # Setup Dask\n",
    "    dask_client = Client(LocalCluster(n_workers=dask_shards))  \n",
    "    \n",
    "    # Create save-to folder if needed\n",
    "    model_dir = os.path.dirname(model_filepath)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Get data\n",
    "    df = context.read(context, features_table, train_on_last, dask_shards) \n",
    "\n",
    "    # Split to Train / Test datasets\n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets_from_data(context,\n",
    "                                                                     df, \n",
    "                                                                     metrics, \n",
    "                                                                     labels, \n",
    "                                                                     train_size)\n",
    "    \n",
    "    # Persist to memory to ensure fast computation on training\n",
    "    X_train = dask_client.persist(X_train)\n",
    "    X_test = dask_client.persist(X_test)\n",
    "    y_train = dask_client.persist(y_train)\n",
    "    y_test = dask_client.persist(y_test)\n",
    "    \n",
    "    # Train\n",
    "    params = {'objective': 'binary:logistic', 'nround': 1000, \n",
    "              'max_depth': 3, 'eta': 0.01, 'subsample': 0.5, \n",
    "              'min_child_weight': 1}\n",
    "    model = dxgb.train(dask_client, params, X_train, y_train)\n",
    "    \n",
    "    # Score\n",
    "    predictions = dxgb.predict(dask_client, model, X_test)\n",
    "    \n",
    "    score = roc_auc_score(y_test.compute(), predictions.compute())\n",
    "    context.log_result('accuracy', score)\n",
    "    \n",
    "    # Save model\n",
    "    model.save_model(model_filepath)\n",
    "    context.log_artifact('model', local_path=model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dask_xgboost(context, \n",
    "            save_to_tsdb=0,\n",
    "            labels='is_error',\n",
    "            metrics=['cpu_utilization', 'throughput', 'latency', 'packet_loss'],\n",
    "            features_table='/User/netops_features_parquet',\n",
    "            model_filepath='/User/netops/models/netops.model',\n",
    "            train_on_last='7d',\n",
    "            train_size=0.7,\n",
    "            dask_shards=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function, mount_v3io, mlconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-09 10:38:38,510 starting remote build, image: .mlrun/func-netops-trainer-latest\n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name daskdev/dask to daskdev/dask \n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name daskdev/dask to daskdev/dask \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image daskdev/dask          \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:2ac5385ebc20fe2982a22f8fcf3cf765e7a01dc5e5003b42aa44493af0a06438: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image daskdev/dask          \n",
      "\u001b[36mINFO\u001b[0m[0000] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image daskdev/dask          \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:2ac5385ebc20fe2982a22f8fcf3cf765e7a01dc5e5003b42aa44493af0a06438: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image daskdev/dask          \n",
      "\u001b[36mINFO\u001b[0m[0000] Unpacking rootfs as cmd RUN pip install v3io_frames requires it. \n",
      "\u001b[36mINFO\u001b[0m[0010] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0015] WORKDIR /run                                 \n",
      "\u001b[36mINFO\u001b[0m[0015] cmd: workdir                                 \n",
      "\u001b[36mINFO\u001b[0m[0015] Changed working directory to /run            \n",
      "\u001b[36mINFO\u001b[0m[0015] RUN pip install v3io_frames                  \n",
      "\u001b[36mINFO\u001b[0m[0015] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0015] args: [-c pip install v3io_frames]           \n",
      "Collecting v3io_frames\n",
      "  Downloading https://files.pythonhosted.org/packages/83/60/31278218d6f7dfff24e16decf82f44bb0a47c0146f9fd4a3897dc853f9be/v3io_frames-0.6.9-py3-none-any.whl\n",
      "Collecting grpcio-tools>=1.16.0 (from v3io_frames)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/14/e776756b4469bc4ac4b39938550e0e859dd5fef5a2ead5e49cab2764f96e/grpcio_tools-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
      "Collecting googleapis-common-protos>=1.5.3 (from v3io_frames)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Requirement already satisfied: requests>=2.19.1 in /opt/conda/lib/python3.7/site-packages (from v3io_frames) (2.22.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.7/site-packages (from v3io_frames) (0.25.2)\n",
      "Collecting protobuf>=3.5.0.post1 (from grpcio-tools>=1.16.0->v3io_frames)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/14/f5c294f1e36a031f165128c25feba93b3116f15a74398d0b2747ed75744f/protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "Collecting grpcio>=1.26.0 (from grpcio-tools>=1.16.0->v3io_frames)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/b3/0052e38c640d52b710e235b15821cc3c61d0065bf54e70a44550ef127349/grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.1->v3io_frames) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.1->v3io_frames) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.1->v3io_frames) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.1->v3io_frames) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.4->v3io_frames) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.4->v3io_frames) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.4->v3io_frames) (1.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.5.0.post1->grpcio-tools>=1.16.0->v3io_frames) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.5.0.post1->grpcio-tools>=1.16.0->v3io_frames) (41.4.0)\n",
      "Building wheels for collected packages: googleapis-common-protos\n",
      "  Building wheel for googleapis-common-protos (setup.py): started\n",
      "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
      "  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.6.0-cp37-none-any.whl size=77577 sha256=d800195267d9ad51491f3a13da53a3aee4e5c13de2bb344ed8a63da560191725\n",
      "  Stored in directory: /root/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built googleapis-common-protos\n",
      "Installing collected packages: protobuf, grpcio, grpcio-tools, googleapis-common-protos, v3io-frames\n",
      "Successfully installed googleapis-common-protos-1.6.0 grpcio-1.26.0 grpcio-tools-1.26.0 protobuf-3.11.2 v3io-frames-0.6.9\n",
      "\u001b[36mINFO\u001b[0m[0020] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0022] RUN pip install 'fsspec>=0.3.3'              \n",
      "\u001b[36mINFO\u001b[0m[0022] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0022] args: [-c pip install 'fsspec>=0.3.3']       \n",
      "Requirement already satisfied: fsspec>=0.3.3 in /opt/conda/lib/python3.7/site-packages (0.6.2)\n",
      "\u001b[36mINFO\u001b[0m[0022] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0023] RUN pip install pyarrow                      \n",
      "\u001b[36mINFO\u001b[0m[0023] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0023] args: [-c pip install pyarrow]               \n",
      "Collecting pyarrow\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/ee/fd2d696eff911f76ed14feeb51e6db6783dd04abd9b8e14be4cbf48d6088/pyarrow-0.15.1-cp37-cp37m-manylinux2010_x86_64.whl (59.2MB)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.17.3)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-0.15.1\n",
      "\u001b[36mINFO\u001b[0m[0027] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0033] RUN pip install dask-ml                      \n",
      "\u001b[36mINFO\u001b[0m[0033] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0033] args: [-c pip install dask-ml]               \n",
      "Collecting dask-ml\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/ee/65f5b61f0f40b3709b91920bfa9cb4820f542a514590e024f746304c7443/dask_ml-1.2.0-py3-none-any.whl (124kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from dask-ml) (19.2)\n",
      "Collecting scipy (from dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)\n",
      "Collecting scikit-learn>=0.21 (from dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/db/7d8204ddba84ab5d1e4fd1af8f82bbe39c589488bee71e45c662f4144010/scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.7/site-packages (from dask-ml) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from dask-ml) (1.17.3)\n",
      "Collecting numba (from dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/d7/9f0a9e1b173fddc77ad6cb8943bc433a850c2a6d3fa5c02a086400ba0c8f/numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7MB)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from dask-ml) (2.9.1)\n",
      "Collecting multipledispatch>=0.4.9 (from dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: distributed>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from dask-ml) (2.9.1)\n",
      "Collecting dask-glm>=0.2.0 (from dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/ee/36c6e0e7b51e08406e5c3bb036f35adb77bd0a89335437b2e6f03c948f1a/dask_glm-0.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->dask-ml) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->dask-ml) (1.12.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.21->dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.4->dask-ml) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.4->dask-ml) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->dask-ml) (41.4.0)\n",
      "Collecting llvmlite>=0.31.0dev0 (from numba->dask-ml)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/10/d02c0ac683fc47ecda3426249509cf771d748b6a2c0e9d5ebbee76a7b80a/llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /opt/conda/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (0.10.0)\n",
      "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in /opt/conda/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (1.1.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in /opt/conda/lib/python3.7/site-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (0.6.2)\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (7.0)\n",
      "Requirement already satisfied: tblib in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (1.6.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (1.0.0)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (2.1.0)\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (6.0.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (5.1.2)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.4.0->dask-ml) (5.6.7)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[array,dataframe]>=2.4.0->dask-ml) (0.2.0)\n",
      "Requirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.4.0->dask-ml) (1.0.1)\n",
      "Installing collected packages: scipy, joblib, scikit-learn, llvmlite, numba, multipledispatch, dask-glm, dask-ml\n",
      "Successfully installed dask-glm-0.2.0 dask-ml-1.2.0 joblib-0.14.1 llvmlite-0.31.0 multipledispatch-0.6.0 numba-0.47.0 scikit-learn-0.22.1 scipy-1.4.1\n",
      "\u001b[36mINFO\u001b[0m[0042] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0050] RUN pip install dask-xgboost --upgrade       \n",
      "\u001b[36mINFO\u001b[0m[0050] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0050] args: [-c pip install dask-xgboost --upgrade] \n",
      "Collecting dask-xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/bd/d69f0546e7652daa7717aa44ef5346e023e7dd6cc6a50e397872dee27add/dask_xgboost-0.1.9-py2.py3-none-any.whl\n",
      "Collecting xgboost (from dask-xgboost)\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
      "Requirement already satisfied, skipping upgrade: distributed>=1.15.2 in /opt/conda/lib/python3.7/site-packages (from dask-xgboost) (2.9.1)\n",
      "Requirement already satisfied, skipping upgrade: dask in /opt/conda/lib/python3.7/site-packages (from dask-xgboost) (2.9.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost->dask-xgboost) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost->dask-xgboost) (1.17.3)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: msgpack in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (5.6.7)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.7.4 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tblib in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=1.15.2->dask-xgboost) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=1.15.2->dask-xgboost) (1.0.1)\n",
      "Installing collected packages: xgboost, dask-xgboost\n",
      "Successfully installed dask-xgboost-0.1.9 xgboost-0.90\n",
      "\u001b[36mINFO\u001b[0m[0055] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0065] RUN pip install mlrun                        \n",
      "\u001b[36mINFO\u001b[0m[0065] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0065] args: [-c pip install mlrun]                 \n",
      "Collecting mlrun\n",
      "  Downloading https://files.pythonhosted.org/packages/28/f3/390a683288f61e8cacfa3b2313ec1a989c8799f70c45cb7ebd934b050a63/mlrun-0.4.1-py3-none-any.whl (107kB)\n",
      "Collecting tabulate<=0.8.3,>=0.8.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "Collecting nuclio-jupyter>=0.8.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/16/c49184a3629415d47945a5a80ae4f8e92267983ada23df7160766c1d2055/nuclio_jupyter-0.8.0-py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from mlrun) (0.25.2)\n",
      "Collecting sqlalchemy==1.3.11 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/34/5c/0e1d7ad0ca52544bb12f9cb8d5cc454af45821c92160ffedd38db0a317f6/SQLAlchemy-1.3.11.tar.gz (6.0MB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlrun) (7.0)\n",
      "Collecting aiohttp>=3.5.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/71/6000eacb8923d9fd07aa8784a8fab4f022ae697f3c2456d7dca75c743dd6/aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2MB)\n",
      "Collecting nuclio-sdk>=0.0.3 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/23/ce0d7bba26365c7e94cae1ccfa41323d43490c622fa8f1207aabfc4e5a3d/nuclio_sdk-0.0.5-py2.py3-none-any.whl\n",
      "Collecting Flask>=1.1.1 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
      "Collecting nest-asyncio>=1.0.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/01/55100e0dda328f2181b719bddc5af0a24487de81038747d676d5be7ef879/nest_asyncio-1.2.1-py3-none-any.whl\n",
      "Collecting kfp>=0.1.29 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/3f/27bcb5a55534f7c869132853240986dd34aa0e1cae9095f3f6758882da89/kfp-0.1.39.tar.gz (112kB)\n",
      "Collecting GitPython>=2.1.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
      "Collecting gunicorn==19.9.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl (112kB)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from mlrun) (5.1.2)\n",
      "Requirement already satisfied: requests>=2.20.1 in /opt/conda/lib/python3.7/site-packages (from mlrun) (2.22.0)\n",
      "Collecting boto3>=1.9 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/15/93f5961dde2d14027e0215733633bd709eb6fb0e9af6d046dea9c4c0769c/boto3-1.10.49-py2.py3-none-any.whl (128kB)\n",
      "Collecting tornado<6,>=5 (from nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)\n",
      "Collecting nbconvert>=5.4 (from nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/6c/05a569e9f703d18aacb89b7ad6075b404e8a4afde2c26b73ca77bb644b14/nbconvert-5.6.1-py2.py3-none-any.whl (455kB)\n",
      "Collecting notebook>=5.7.2 (from nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/69/d2ffaf7efc20ce47469187e3a41e6e03e17b45de5a6559f4e7ab3eace5e1/notebook-6.0.2-py3-none-any.whl (9.7MB)\n",
      "Collecting jupyterlab>=0.35.4 (from nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9a/6e81535ed42ad01ec2a5e8f9e0419108f60fab36e48dc1168fa5e0576a81/jupyterlab-1.2.4-py2.py3-none-any.whl (6.4MB)\n",
      "Collecting ipython>=7.2 (from nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/f3/c8be38ee117d02508bb8b9158eb41ca416f442a6e8e3b3159c2f2d14ed79/ipython-7.11.1-py3-none-any.whl (777kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->mlrun) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->mlrun) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->mlrun) (1.17.3)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.5.0->mlrun) (3.0.4)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/70/54/7cb8eabe7dea1b441a7487ae3a1adb319f2d2e44a062a669f730a24dc474/yarl-1.4.2-cp37-cp37m-manylinux1_x86_64.whl (256kB)\n",
      "Collecting async-timeout<4.0,>=3.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting multidict<5.0,>=4.5 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/e9/7d3ac453ea8fbf3aed9479809ec6093e88e88e495c534c4636ecf7fc8fb9/multidict-4.7.3-cp37-cp37m-manylinux1_x86_64.whl (149kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.15 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "Collecting itsdangerous>=0.24 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.1.1->mlrun) (2.10.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp>=0.1.29->mlrun) (1.24.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kfp>=0.1.29->mlrun) (1.12.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp>=0.1.29->mlrun) (2019.11.28)\n",
      "Collecting google-cloud-storage>=1.13.0 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/13/70354d66a87c92797a4c233c00615d69986e7d7ecfbe6c00c7c237c9d465/google_cloud_storage-1.24.1-py2.py3-none-any.whl (72kB)\n",
      "Collecting kubernetes<=9.0.0,>=8.0.0 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/f7/4f196c55f1c2713d3edc8252c4b45326306eef4dc10048f13916fe446e2b/kubernetes-9.0.0-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting PyJWT>=1.6.4 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cryptography>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from kfp>=0.1.29->mlrun) (2.7)\n",
      "Collecting google-auth>=1.6.1 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
      "Collecting requests_toolbelt>=0.8.0 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "Collecting cloudpickle==1.1.1 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
      "Collecting kfp-server-api<=0.1.37,>=0.1.18 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/ba/4b4f6088fd92e8101f493a2edf6349de951b8c0cf3efac4efa25a997af4a/kfp-server-api-0.1.37.tar.gz\n",
      "Collecting argo-models==2.2.1a (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/53/a92df7c1c793edf2db99b14e428246e4b49b93499a5c9ed013e0aa2416f6/argo-models-2.2.1a0.tar.gz\n",
      "Collecting jsonschema>=3.0.1 (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
      "Collecting Deprecated (from kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Collecting gitdb2>=2.0.0 (from GitPython>=2.1.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.1->mlrun) (2.8)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.49 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/66/6b/8594c74d45f3479f22a53329e39f50f55023ba1a17ce579a29ef811a957f/botocore-1.13.49-py2.py3-none-any.whl (5.9MB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "Collecting entrypoints>=0.2.2 (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl\n",
      "Collecting mistune<2,>=0.8.1 (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/ec/4b43dae793655b7d8a25f76119624350b4d65eb663459eb9603d7f1f0345/mistune-0.8.4-py2.py3-none-any.whl\n",
      "Collecting testpath (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/9e/1a170feaa54f22aeb5a5d16c9015e82234275a3c8ab630b552493f9cb8a9/testpath-0.4.4-py2.py3-none-any.whl (163kB)\n",
      "Collecting jupyter-core (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/82/86437f661875e30682e99d04c13ba6c216f86f5f6ca6ef212d3ee8b6ca11/jupyter_core-4.6.1-py2.py3-none-any.whl (82kB)\n",
      "Collecting nbformat>=4.4 (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/69/87745d03d1964649ef734238b32bf08eb843a6594cb03e8bc77edc8f33e9/nbformat-5.0.3-py3-none-any.whl (169kB)\n",
      "Collecting traitlets>=4.2 (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ab/872a23e29cec3cf2594af7e857f18b687ad21039c1f9b922fac5b9b142d5/traitlets-4.3.3-py2.py3-none-any.whl (75kB)\n",
      "Collecting bleach (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB)\n",
      "Collecting defusedxml (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/06/74/9b387472866358ebc08732de3da6dc48e44b0aacd2ddaa5cb85ab7e986a2/defusedxml-0.6.0-py2.py3-none-any.whl\n",
      "Collecting pygments (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/be/39/32da3184734730c0e4d3fa3b2b5872104668ad6dc1b5a73d8e477e5fe967/Pygments-2.5.2-py2.py3-none-any.whl (896kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz\n",
      "Collecting prometheus-client (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
      "Collecting ipykernel (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/92/8fec943b5b81078399f969f00557804d884c96fcd0bc296e81a2ed4fd270/ipykernel-5.1.3-py3-none-any.whl (116kB)\n",
      "Collecting pyzmq>=17 (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/dd/547bee2080beefe6546c332422cb0f189b3cd71cfff048146cd9ac3751cc/pyzmq-18.1.1-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting terminado>=0.8.1 (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/96/1d9a2c23990aea8f8e0b5c3b6627d03196a73771a17a2d9860bbe9823ab6/terminado-0.8.3-py2.py3-none-any.whl\n",
      "Collecting ipython-genutils (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Collecting jupyter-client>=5.3.4 (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/13/81/fe0eee1bcf949851a120254b1f530ae1e01bdde2d3ab9710c6ff81525061/jupyter_client-5.3.4-py2.py3-none-any.whl (92kB)\n",
      "Collecting Send2Trash (from notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/49/46/c3dc27481d1cc57b9385aff41c474ceb7714f7935b1247194adae45db714/Send2Trash-1.5.0-py3-none-any.whl\n",
      "Collecting jupyterlab-server~=1.0.0 (from jupyterlab>=0.35.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/98/5b87b9d38176bd98f23b58a8fb730e5124618d68571a011abbd38ad4a842/jupyterlab_server-1.0.6-py3-none-any.whl\n",
      "Collecting decorator (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/b7/f329cfdc75f3d28d12c65980e4469e2fa373f1953f5df6e370e84ea2e875/decorator-4.4.1-py2.py3-none-any.whl\n",
      "Collecting pickleshare (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting pexpect; sys_platform != \"win32\" (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun) (41.4.0)\n",
      "Collecting jedi>=0.10 (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/97/55e575a5b49e5c3df9eb3c116c61021d7badf556c816be13bbd7baf55234/jedi-0.15.2-py2.py3-none-any.whl (1.1MB)\n",
      "Collecting backcall (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/1f/e145dd467dc9b0e6f1e64232c03119498dfec497e383f1e8be9f83eaa97e/prompt_toolkit-3.0.2-py3-none-any.whl (344kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask>=1.1.1->mlrun) (1.1.1)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/54/8c5542c0df4c8a92c0b8736ee67abc4daa9ff3734a0119310c125673ac79/google_cloud_core-1.1.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes<=9.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting requests-oauthlib (from kubernetes<=9.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp>=0.1.29->mlrun) (1.0.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp>=0.1.29->mlrun) (1.12.3)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/71/1a1e0ed0981bb6a67bce55a210f168126b7ebd2065958673797ea66489ca/importlib_metadata-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/aa/cdcf7ef88cc0f831b6f14c8c57318824c9de9913fe8de38e46a98c069a35/pyrsistent-0.15.7.tar.gz (107kB)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=2.1.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.14.0,>=1.13.49->boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Collecting webencodings (from bleach->nbconvert>=5.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\n",
      "Collecting ptyprocess; os_name != \"nt\" (from terminado>=0.8.1->notebook>=5.7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl\n",
      "Collecting json5 (from jupyterlab-server~=1.0.0->jupyterlab>=0.35.4->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/30/44/062543d4a6718f99d82e5ecf9140dbdee8a03122f2c34fbd0b0609891707/json5-0.8.5-py2.py3-none-any.whl\n",
      "Collecting parso>=0.5.2 (from jedi>=0.10->ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/b0/90353a5ece0987279837835224dead0c424833a224195683e188d384e06b/parso-0.5.2-py2.py3-none-any.whl (99kB)\n",
      "Collecting wcwidth (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.2->nuclio-jupyter>=0.8.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/58/b4/4850a0ccc6f567cc0ebe7060d20ffd4258b8210efadc259da62dc6ed9c65/wcwidth-0.1.8-py2.py3-none-any.whl\n",
      "Collecting google-api-core<2.0.0dev,>=1.14.0 (from google-cloud-core<2.0dev,>=1.1.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/70/bd363339fc88a1c434655ba03171d46aa2e679e1452cc95a4a8679e76a7a/google_api_core-1.15.0-py2.py3-none-any.whl (69kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp>=0.1.29->mlrun) (2.19)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.1.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun) (3.11.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.1.0->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun) (1.6.0)\n",
      "Collecting more-itertools (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp>=0.1.29->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/03/0604cec1ea13c9f063dd50f900d1a36160334dd3cfb01fd0e638f61b46ba/more_itertools-8.0.2-py3-none-any.whl (40kB)\n",
      "Building wheels for collected packages: tabulate, sqlalchemy, kfp, tornado, kfp-server-api, argo-models, pandocfilters, prometheus-client, backcall, pyrsistent, wrapt\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-cp37-none-any.whl size=23378 sha256=f4defc507cca34bab2fa56c35d84ed65581a00c90c33ac8052eea78d30f9ef09\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Building wheel for sqlalchemy (setup.py): started\n",
      "  Building wheel for sqlalchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.11-cp37-cp37m-linux_x86_64.whl size=1164864 sha256=8d077c9f511914f93582ddba69163f5926f375240d57f6c5a0ab6095dadfd777\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/67/7d/6c41104a1a08ff1a25e260d3edec3ac19203141d1aaa2f0975\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-0.1.39-cp37-none-any.whl size=155801 sha256=6e210d769a483c641f52605d565770a31bdf047ac382e54b0c7ad94cc7011cbb\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/22/3d/36cba93600b97b76217f870dcc076256559ca7237837e36488\n",
      "  Building wheel for tornado (setup.py): started\n",
      "  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Created wheel for tornado: filename=tornado-5.1.1-cp37-cp37m-linux_x86_64.whl size=449842 sha256=48c92b6c77c4bdff3b208495a18a51980e16bbdc651952e4a206528774a323a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-0.1.37-cp37-none-any.whl size=102468 sha256=5a9284a5689f0990ff1a3c17ed1396d5d051ab1b37337c63c75f1cc04e5ed196\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/91/06/c5356e8438626814069fdc8ddd620ad984b1dd389ec44c8f07\n",
      "  Building wheel for argo-models (setup.py): started\n",
      "  Building wheel for argo-models (setup.py): finished with status 'done'\n",
      "  Created wheel for argo-models: filename=argo_models-2.2.1a0-cp37-none-any.whl size=57308 sha256=fdba0c12608a2a8c7e33187d17bb73c6e020bc635a47683689c12a239ca11377\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/5b/6b/20cdc06ddb10caa3a86f5804eb9a90122ae8de0bcf19a468d8\n",
      "  Building wheel for pandocfilters (setup.py): started\n",
      "  Building wheel for pandocfilters (setup.py): finished with status 'done'\n",
      "  Created wheel for pandocfilters: filename=pandocfilters-1.4.2-cp37-none-any.whl size=7857 sha256=ea8671f79b9a16fa95bc4a05b02c9051412066de4be42d475fd18c3aa39b4f68\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/01/56/f1b08a6275acc59e846fa4c1e1b65dbc1919f20157d9e66c20\n",
      "  Building wheel for prometheus-client (setup.py): started\n",
      "  Building wheel for prometheus-client (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41402 sha256=a81392b22d16933935f4237fd9c48ca1eb6aeca1ef122d3bad16e2c2ad482a49\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
      "  Building wheel for backcall (setup.py): started\n",
      "  Building wheel for backcall (setup.py): finished with status 'done'\n",
      "  Created wheel for backcall: filename=backcall-0.1.0-cp37-none-any.whl size=10415 sha256=cf3a5239cc51b6b9504320b237528ef74762e51653d6a00b8aa15c63a86ce1c3\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.15.7-cp37-cp37m-linux_x86_64.whl size=56531 sha256=041b67fb6f93704b371e96adb574560cc188b16fea855bae9125c43e8d5f4d36\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/78/ac/f26a78a989cd97f90981d96a560d7e1da5e1307284301d94e8\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.2-cp37-none-any.whl size=19592 sha256=5e4dac54b7194975da2c289e7741c6de5bf370c22303219869cb50b3067df2a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "Successfully built tabulate sqlalchemy kfp tornado kfp-server-api argo-models pandocfilters prometheus-client backcall pyrsistent wrapt\n",
      "Installing collected packages: tabulate, tornado, jmespath, docutils, botocore, s3transfer, boto3, nuclio-sdk, entrypoints, mistune, testpath, ipython-genutils, decorator, traitlets, jupyter-core, more-itertools, zipp, importlib-metadata, pyrsistent, attrs, jsonschema, nbformat, webencodings, bleach, defusedxml, pygments, pandocfilters, nbconvert, prometheus-client, pyzmq, jupyter-client, pickleshare, ptyprocess, pexpect, parso, jedi, backcall, wcwidth, prompt-toolkit, ipython, ipykernel, terminado, Send2Trash, notebook, json5, jupyterlab-server, jupyterlab, nuclio-jupyter, sqlalchemy, multidict, yarl, async-timeout, aiohttp, Werkzeug, itsdangerous, Flask, nest-asyncio, google-resumable-media, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-api-core, google-cloud-core, google-cloud-storage, websocket-client, oauthlib, requests-oauthlib, kubernetes, PyJWT, requests-toolbelt, cloudpickle, kfp-server-api, argo-models, wrapt, Deprecated, kfp, smmap2, gitdb2, GitPython, gunicorn, mlrun\n",
      "  Found existing installation: tornado 6.0.3\n",
      "    Uninstalling tornado-6.0.3:\n",
      "      Successfully uninstalled tornado-6.0.3\n",
      "  Found existing installation: cloudpickle 1.2.2\n",
      "    Uninstalling cloudpickle-1.2.2:\n",
      "      Successfully uninstalled cloudpickle-1.2.2\n",
      "Successfully installed Deprecated-1.2.7 Flask-1.1.1 GitPython-3.0.5 PyJWT-1.7.1 Send2Trash-1.5.0 Werkzeug-0.16.0 aiohttp-3.6.2 argo-models-2.2.1a0 async-timeout-3.0.1 attrs-19.3.0 backcall-0.1.0 bleach-3.1.0 boto3-1.10.49 botocore-1.13.49 cachetools-4.0.0 cloudpickle-1.1.1 decorator-4.4.1 defusedxml-0.6.0 docutils-0.15.2 entrypoints-0.3 gitdb2-2.0.6 google-api-core-1.15.0 google-auth-1.10.0 google-cloud-core-1.1.0 google-cloud-storage-1.24.1 google-resumable-media-0.5.0 gunicorn-19.9.0 importlib-metadata-1.3.0 ipykernel-5.1.3 ipython-7.11.1 ipython-genutils-0.2.0 itsdangerous-1.1.0 jedi-0.15.2 jmespath-0.9.4 json5-0.8.5 jsonschema-3.2.0 jupyter-client-5.3.4 jupyter-core-4.6.1 jupyterlab-1.2.4 jupyterlab-server-1.0.6 kfp-0.1.39 kfp-server-api-0.1.37 kubernetes-9.0.0 mistune-0.8.4 mlrun-0.4.1 more-itertools-8.0.2 multidict-4.7.3 nbconvert-5.6.1 nbformat-5.0.3 nest-asyncio-1.2.1 notebook-6.0.2 nuclio-jupyter-0.8.0 nuclio-sdk-0.0.5 oauthlib-3.1.0 pandocfilters-1.4.2 parso-0.5.2 pexpect-4.7.0 pickleshare-0.7.5 prometheus-client-0.7.1 prompt-toolkit-3.0.2 ptyprocess-0.6.0 pyasn1-0.4.8 pyasn1-modules-0.2.7 pygments-2.5.2 pyrsistent-0.15.7 pyzmq-18.1.1 requests-oauthlib-1.3.0 requests-toolbelt-0.9.1 rsa-4.0 s3transfer-0.2.1 smmap2-2.0.5 sqlalchemy-1.3.11 tabulate-0.8.3 terminado-0.8.3 testpath-0.4.4 tornado-5.1.1 traitlets-4.3.3 wcwidth-0.1.8 webencodings-0.5.1 websocket-client-0.57.0 wrapt-1.11.2 yarl-1.4.2 zipp-0.6.0\n",
      "\u001b[36mINFO\u001b[0m[0090] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0093] Adding whiteout for /opt/conda/lib/python3.7/site-packages/cloudpickle-1.2.2.dist-info \n",
      "\u001b[36mINFO\u001b[0m[0093] Adding whiteout for /opt/conda/lib/python3.7/site-packages/cloudpickle/cloudpickle_fast.py \n",
      "\u001b[36mINFO\u001b[0m[0093] Adding whiteout for /opt/conda/lib/python3.7/site-packages/tornado/py.typed \n",
      "\u001b[36mINFO\u001b[0m[0093] Adding whiteout for /opt/conda/lib/python3.7/site-packages/tornado/speedups.cpython-37m-x86_64-linux-gnu.so \n",
      "\u001b[36mINFO\u001b[0m[0093] Adding whiteout for /opt/conda/lib/python3.7/site-packages/tornado-6.0.3.dist-info \n",
      "\u001b[36mINFO\u001b[0m[0100] ENV PYTHONPATH /run                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = code_to_function(name='trainer',\n",
    "                           runtime='job',\n",
    "                           project='netops',\n",
    "                           handler='trainer_dask_xgboost')\n",
    "trainer = trainer.apply(mount_v3io())\n",
    "trainer.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f79f580dcf8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.with_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-09 11:37:46,190 starting run trainer_dask_xgboost uid=e720db2eb8724ceda7898bc6def5acc0  -> http://mlrun-api:8080\n",
      "[11:37:56] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[11:37:56] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[mlrun] 2020-01-09 11:37:55,416 Reading data from: /User/netops_features_parquet/20200102T074701-20200102T084511\n",
      "\n",
      "[mlrun] 2020-01-09 11:37:57,087 run executed, status=completed\n",
      "final state: succeeded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"e720db2eb8724ceda7898bc6def5acc0\">...f5acc0</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 09 11:37:53</td>\n",
       "      <td>completed</td>\n",
       "      <td>trainer</td>\n",
       "      <td><div class=\"dictlist\">host=trainer-dask-xgboost-d2sgp</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">dask_shards=4</div><div class=\"dictlist\">features_table=/User/netops_features_parquet</div><div class=\"dictlist\">labels=['is_error']</div><div class=\"dictlist\">metrics=['cpu_utilization', 'throughput', 'latency', 'packet_loss']</div><div class=\"dictlist\">model_filepath=/User/netops/models/model.bst</div><div class=\"dictlist\">save_to_tsdb=0</div><div class=\"dictlist\">windows={'hourly': 180, 'minutely': 3}</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.9990536277602523</div></td>\n",
       "      <td><div title=\"/User/netops/models/model.bst\">model</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result9d6b7af3-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result9d6b7af3-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result9d6b7af3\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result9d6b7af3-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run e720db2eb8724ceda7898bc6def5acc0  , !mlrun logs e720db2eb8724ceda7898bc6def5acc0 \n",
      "[mlrun] 2020-01-09 11:38:05,488 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'windows': {'minutely': 3, \n",
    "                'hourly': 3*60},\n",
    "    'metrics': ['cpu_utilization', 'throughput', 'latency', 'packet_loss'],\n",
    "    'labels': ['is_error'],\n",
    "    'save_to_tsdb': 0,\n",
    "    'features_table': '/User/netops_features_parquet',\n",
    "    'model_filepath': '/User/netops/models/model.bst',\n",
    "    'dask_shards': 4,\n",
    "}\n",
    "\n",
    "run = trainer.run(params=params, watch=True, handler='trainer_dask_xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
