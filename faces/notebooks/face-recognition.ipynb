{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using mlrun with OpenCV And scikit-learn\n",
    " A complete pipeline of data processing, model training and serving function deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install mlrun and kubeflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlrun\n",
    "!pip install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart jupyter kernel after initial installations\n",
    "Either restart manually, or run the following code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies for the code and set config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change following magic command to %%nuclio cmd -c if the following packages are already installed locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%nuclio cmd\n",
    "pip install cmake\n",
    "pip install dlib\n",
    "pip install face_recognition\n",
    "pip install opencv-contrib-python\n",
    "pip install imutils\n",
    "pip install sklearn \n",
    "pip install pandas\n",
    "pip install joblib\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables and perform necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/User/demos/face-recognition/dataset/'\n",
    "ARTIFACTS_PATH = '/User/demos/face-recognition/artifacts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlrun.artifacts import TableArtifact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import v3io_frames as v3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and define mlrun functions for the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, NewTask, mount_v3io\n",
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(context):\n",
    "    \n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "    \n",
    "    # If no train images exist in the predefined path we will train the model on a small dataset of movie actresses\n",
    "    if not os.path.exists(DATA_PATH + 'input'):\n",
    "        os.makedirs(DATA_PATH + 'input')\n",
    "        resp = urlopen('https://iguazio-public.s3.amazonaws.com/roy-actresses/Actresses.zip')\n",
    "        zip_ref = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "        zip_ref.extractall(DATA_PATH + 'input')\n",
    "        zip_ref.close()\n",
    "          \n",
    "    \n",
    "    idx_file_path = ARTIFACTS_PATH+\"idx2name.csv\"\n",
    "    if os.path.exists(idx_file_path):\n",
    "        idx2name_df = pd.read_csv(idx_file_path)\n",
    "    else:\n",
    "        idx2name_df = pd.DataFrame(columns=['value', 'name'])\n",
    "    \n",
    "    \n",
    "    #creates a mapping of classes(person's names) to target value\n",
    "    new_classes_names = [f for f in os.listdir(DATA_PATH + 'input') if not '.ipynb' in f and f not in idx2name_df['name'].values]\n",
    "    \n",
    "    initial_len = len(idx2name_df)\n",
    "    final_len = len(idx2name_df) + len(new_classes_names)\n",
    "    for i in range(initial_len, final_len):\n",
    "        idx2name_df.loc[i] = {'value': i, 'name': new_classes_names.pop()}\n",
    "        \n",
    "    name2idx = idx2name_df.set_index('name')['value'].to_dict()\n",
    "            \n",
    "    \n",
    "    #log name to index mapping into mlrun context\n",
    "    context.log_artifact(TableArtifact('idx2name', df=idx2name_df), src_path='idx2name.csv')\n",
    "    \n",
    "    #generates a list of paths to labeled images \n",
    "    imagePaths = [f for f in paths.list_images(DATA_PATH + 'input') if not '.ipynb' in f]\n",
    "    knownEncodings = []\n",
    "    knownLabels = []\n",
    "    fileNames = []\n",
    "    urls = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "        #extracts label (person's name) of the image\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        #prepares to relocate image after extracting features\n",
    "        file_name = imagePath.split(os.path.sep)[-1]\n",
    "        new_path = DATA_PATH + 'processed/' + file_name \n",
    "        \n",
    "        #converts image format to RGB for comptability with face_recognition library\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #detects coordinates of faces bounding boxes\n",
    "        boxes = face_recognition.face_locations(rgb, model='hog')\n",
    "        \n",
    "        #computes embeddings for detected faces\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        #this code assumes that a person's folder in the dataset does not contain an image with a face other then his own\n",
    "        for enc in encodings:\n",
    "            file_name = name + '_' + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))                                                            \n",
    "            knownEncodings.append(enc)\n",
    "            knownLabels.append([name2idx[name]])\n",
    "            fileNames.append(file_name)\n",
    "            urls.append(new_path)\n",
    "        \n",
    "        #move image to processed images directory\n",
    "        shutil.move(imagePath, new_path)\n",
    "        \n",
    "    #saves computed encodings to avoid repeating computations\n",
    "    df_x = pd.DataFrame(knownEncodings, columns=['c' + str(i).zfill(3) for i in range(128)]).reset_index(drop=True)\n",
    "    df_y = pd.DataFrame(knownLabels, columns=['label']).reset_index(drop=True)\n",
    "    df_details = pd.DataFrame([['initial training']*3]*len(df_x), columns=['imgUrl', 'camera', 'time'])\n",
    "    df_details['time'] = [datetime.datetime.utcnow()]*len(df_x)\n",
    "    df_details['imgUrl'] = urls\n",
    "    data_df = pd.concat([df_x, df_y, df_details], axis=1)\n",
    "    data_df['fileName'] = fileNames\n",
    "    \n",
    "    client.write(backend='kv', table='iguazio/demos/face-recognition/artifacts/encodings', dfs=data_df, index_cols=['fileName'])\n",
    "    with open('artifacts/encodings_path.txt', 'w+') as f:\n",
    "        f.write('iguazio/demos/face-recognition/artifacts/encodings')\n",
    "    context.log_artifact('encodings_path', src_path=f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, processed_data, model_name='model.bst'):\n",
    "    #trains classifier\n",
    "    context.logger.info('Client')\n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\" )\n",
    "    with open(processed_data.url, 'r') as f:\n",
    "        t = f.read()\n",
    "    \n",
    "    data_df = client.read(backend=\"kv\", table=t, reset_index=False)\n",
    "    \n",
    "    X_train = data_df[['c'+str(i).zfill(3) for i in range(128)]].values\n",
    "    y_train = data_df['label'].values\n",
    "    \n",
    "    model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X_train, y_train)\n",
    "    \n",
    "    context.logger.info('Save model')\n",
    "    #saves and logs model into mlrun context\n",
    "    joblib.dump(model, model_name)\n",
    "    context.log_artifact('model', src_path=model_name, labels={'framework': 'sklearn_classifier'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7fc92dc7e9e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serving function\n",
    "serving_function = code_to_function(name='recognize-faces', \n",
    "                                      filename='./nuclio-face-prediction.ipynb',\n",
    "                                      runtime='nuclio')\n",
    "serving_function.with_http(workers=2).add_volume('User','~/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline functions locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2019-12-02 14:05:45,721 starting run encode_images uid=8a3ae21f24914f488f1198f74bede3d4  -> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"8a3ae21f24914f488f1198f74bede3d4\">...ede3d4</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 02 14:05:45</td>\n",
       "      <td>completed</td>\n",
       "      <td>encode_images</td>\n",
       "      <td><div class=\"dictlist\">kind=handler</div><div class=\"dictlist\">owner=iguazio</div><div class=\"dictlist\">host=jupyter-omympcgsri-dfhpb-6c4cc55b44-5hdb4</div></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulte13f9eab\" title=\"/files/demos/face-recognition/artifacts/idx2name.csv\">idx2name</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"resulte13f9eab\" title=\"/files/demos/face-recognition/artifacts/artifacts/encodings_path.txt\">encodings_path</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resulte13f9eab-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resulte13f9eab-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resulte13f9eab\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resulte13f9eab-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type result.show() to see detailed results/progress or use CLI:\n",
      "!mlrun get run --uid 8a3ae21f24914f488f1198f74bede3d4 \n",
      "[mlrun] 2019-12-02 14:05:46,031 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "task = NewTask(handler=encode_images, out_path=ARTIFACTS_PATH)\n",
    "run = new_function().run(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = NewTask(handler=train, inputs={'processed_data': run.outputs['encodings_path']}, out_path=ARTIFACTS_PATH)\n",
    "train = new_function().run(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function from notebook and build image\n",
    "supposed to take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = code_to_function('face-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.build(image='mlrun/face_recognition:latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='face recognition pipeline',\n",
    "    description='Creates and deploys a face recognition model'\n",
    ")\n",
    "def face_recognition_pipeline():\n",
    "    fn.with_code()\n",
    "    \n",
    "    encode = fn.as_step(name='encode-images', handler='encode_images', out_path=ARTIFACTS_PATH, outputs=['idx2name', 'encodings_path']).apply(mount_v3io())\n",
    "    \n",
    "    train = fn.as_step(name='train', handler='train', out_path=ARTIFACTS_PATH, outputs=['model'], \n",
    "                               inputs={'processed_data': encode.outputs['encodings_path']}).apply(mount_v3io())\n",
    "    \n",
    "    deploy = serving_function.deploy_step(project='default', models={'face_rec_v1': train.outputs['model']})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes compile pipeline code\n",
    "kfp.compiler.Compiler().compile(face_recognition_pipeline, 'face_rec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(face_recognition_pipeline, arguments=arguments, run_name='face_rec_1', experiment_name='face_rec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
