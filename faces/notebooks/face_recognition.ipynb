{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using mlrun with OpenCV And scikit-learn\n",
    " A complete pipeline of data processing, model training and serving function deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install mlrun and kubeflow pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlrun\n",
    "!pip install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies for the code and set config \n",
    "\n",
    "It is possible that after installing dependencies locally, you will need to restart Jupyter kernel to successfully import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd \n",
    "pip install cmake\n",
    "pip install dlib\n",
    "pip install face_recognition\n",
    "pip install opencv-contrib-python\n",
    "pip install imutils\n",
    "pip install sklearn \n",
    "pip install pandas\n",
    "pip install joblib\n",
    "pip install v3io_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare global variables and perform necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/User/demos/face-recognition/dataset/'\n",
    "ARTIFACTS_PATH = '/User/demos/face-recognition/artifacts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlrun.artifacts import TableArtifact\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import v3io_frames as v3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and define mlrun functions for the pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "from mlrun import new_function, code_to_function, NewTask, mount_v3io\n",
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(context):\n",
    "    \n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "    \n",
    "    # If no train images exist in the predefined path we will train the model on a small dataset of movie actresses\n",
    "    if not os.path.exists(DATA_PATH + 'input'):\n",
    "        os.makedirs(DATA_PATH + 'input')\n",
    "        resp = urlopen('https://iguazio-public.s3.amazonaws.com/roy-actresses/Actresses.zip')\n",
    "        zip_ref = zipfile.ZipFile(BytesIO(resp.read()), 'r')\n",
    "        zip_ref.extractall(DATA_PATH + 'input')\n",
    "        zip_ref.close()\n",
    "        \n",
    "    \n",
    "    #creates a mapping of classes(person's names) to target value\n",
    "    classes_names = [f for f in os.listdir(DATA_PATH + 'input') if not '.ipynb' in f]\n",
    "    \n",
    "    name2idx = {}\n",
    "    idx2name = {}\n",
    "    \n",
    "    for (i, name) in enumerate(classes_names):\n",
    "        idx2name[i] = name\n",
    "        name2idx[name] = i\n",
    "    value2name_dict = {'value':[i for i in idx2name.keys()], 'name':[n for n in idx2name.values()]}\n",
    "    \n",
    "    #log name to index mapping into mlrun context\n",
    "    mapping_df = pd.DataFrame(value2name_dict)\n",
    "    mapping_df['value'] = mapping_df['value'].astype('str')\n",
    "    context.log_artifact(TableArtifact('idx2name', df=mapping_df), src_path='idx2name.csv')\n",
    "    \n",
    "    #generates a list of paths to labeled images \n",
    "    imagePaths = [f for f in paths.list_images(DATA_PATH + 'input') if not '.ipynb' in f]\n",
    "    knownEncodings = []\n",
    "    knownLabels = []\n",
    "    fileNames = []\n",
    "    urls = []\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "        #extracts label (person's name) of the image\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        #converts image format to RGB for comptability with face_recognition library\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #detects coordinates of faces bounding boxes\n",
    "        boxes = face_recognition.face_locations(rgb, model='hog')\n",
    "        \n",
    "        #computes embeddings for detected faces\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        #this code assumes that a person's folder in the dataset does not contain an image with a face other then his own\n",
    "        for enc in encodings:\n",
    "            file_name = name + '_' + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))                                                            \n",
    "            knownEncodings.append(enc)\n",
    "            knownLabels.append([name2idx[name]])\n",
    "            fileNames.append(file_name)\n",
    "            urls.append(imagePath)\n",
    "            \n",
    "    #saves computed encodings to avoid repeating computations\n",
    "    df_x = pd.DataFrame(knownEncodings, columns=['c' + str(i).zfill(3) for i in range(128)]).reset_index(drop=True)\n",
    "    df_y = pd.DataFrame(knownLabels, columns=['label']).reset_index(drop=True)\n",
    "    df_details = pd.DataFrame([['initial training']*3]*len(df_x), columns=['imgUrl', 'camera', 'time'])\n",
    "    df_details['time'] = [datetime.datetime.utcnow()]*len(df_x)\n",
    "    df_details['imgUrl'] = urls\n",
    "    data_df = pd.concat([df_x, df_y, df_details], axis=1)\n",
    "    data_df['fileName'] = fileNames\n",
    "    client.write(backend='kv', table='iguazio/demos/face-recognition/artifacts/encodings', dfs=data_df, index_cols=['fileName'])\n",
    "    with open('encodings_path.txt', 'w+') as f:\n",
    "        f.write('iguazio/demos/face-recognition/artifacts/encodings')\n",
    "    context.log_artifact('encodings_path', src_path=f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, processed_data, model_name='model.bst'):\n",
    "    #trains classifier\n",
    "    client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "    with open(processed_data.url, 'r') as f:\n",
    "        t = f.read()\n",
    "    data_df = client.read(backend=\"kv\", table=t, reset_index=False)\n",
    "\n",
    "    X_train = data_df[['c'+str(i).zfill(3) for i in range(128)]].values\n",
    "    y_train = data_df['label'].values\n",
    "    model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X_train, y_train)\n",
    "    \n",
    "    #saves and logs model into mlrun context\n",
    "    joblib.dump(model, model_name)\n",
    "    context.log_artifact('model', src_path=model_name, labels={'framework': 'sklearn_classifier'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serving function\n",
    "serving_function = code_to_function(name='recognize-faces', \n",
    "                                      filename='./nuclio_face_prediction.ipynb',\n",
    "                                      runtime='nuclio')\n",
    "serving_function.with_http(workers=2).add_volume('User','~/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipeline functions locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = NewTask(handler=encode_images, out_path=ARTIFACTS_PATH)\n",
    "run = new_function().run(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = NewTask(handler=train, inputs={'processed_data': run.outputs['encodings_path']}, out_path=ARTIFACTS_PATH)\n",
    "train = new_function().run(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function from notebook and build image\n",
    "supposed to take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = code_to_function('face-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.build(image='mlrun/face_recognition:latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='face recognition pipeline',\n",
    "    description='Creates and deploys a face recognition model'\n",
    ")\n",
    "def face_recognition_pipeline():\n",
    "    fn.with_code()\n",
    "    \n",
    "    encode = fn.as_step(name='encode-images', handler='encode_images', out_path=ARTIFACTS_PATH, outputs=['idx2name', 'encodings_path']).apply(mount_v3io())\n",
    "    \n",
    "    train = fn.as_step(name='train', handler='train', out_path=ARTIFACTS_PATH, outputs=['model'], \n",
    "                               inputs={'processed_data': encode.outputs['encodings_path']}).apply(mount_v3io())\n",
    "    \n",
    "    deploy = serving_function.deploy_step(project='default', models={'face_rec_v1': train.outputs['model']})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace='default-tenant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For debug purposes compile pipeline code\n",
    "kfp.compiler.Compiler().compile(face_recognition_pipeline, 'face_rec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "run_result = client.create_run_from_pipeline_func(face_recognition_pipeline, arguments=arguments, run_name='face_rec_1', experiment_name='face_rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
