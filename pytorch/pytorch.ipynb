{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !python -m pip install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    !python -m pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import (Checkpoint,\n",
    "                              TrainEndCheckpoint,\n",
    "                              LoadInitState)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pickle import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=100_000,\n",
    "    n_features=20,\n",
    "    n_informative=8,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.5],\n",
    "    shuffle=True,\n",
    "    random_state=1)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = Checkpoint(dirname='pytorch/checkpoint')\n",
    "train_end_cp = TrainEndCheckpoint(dirname='pytorch/checkpoint')\n",
    "load_state = LoadInitState(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=16, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "       #X = self.sigmoid(self.output(X))\n",
    "        X = F.softmax(self.output(X), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetBinaryClassifier(\n",
    "    MyModule,\n",
    "    device='cuda',\n",
    "    max_epochs=15,\n",
    "    lr=0.01,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[cp, train_end_cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module': __main__.MyModule,\n",
       " 'criterion': torch.nn.modules.loss.NLLLoss,\n",
       " 'optimizer': torch.optim.sgd.SGD,\n",
       " 'lr': 0.01,\n",
       " 'max_epochs': 15,\n",
       " 'batch_size': 128,\n",
       " 'iterator_train': torch.utils.data.dataloader.DataLoader,\n",
       " 'iterator_valid': torch.utils.data.dataloader.DataLoader,\n",
       " 'dataset': skorch.dataset.Dataset,\n",
       " 'train_split': <skorch.dataset.CVSplit object at 0x7f78a26e4810>,\n",
       " 'callbacks': [<skorch.callbacks.training.Checkpoint at 0x7f78a21fa7d0>,\n",
       "  <skorch.callbacks.training.TrainEndCheckpoint at 0x7f78a21fa790>],\n",
       " 'warm_start': False,\n",
       " 'verbose': 1,\n",
       " 'device': 'cuda',\n",
       " 'iterator_train__shuffle': True,\n",
       " 'history_': None,\n",
       " 'initialized_': False,\n",
       " 'virtual_params_': {},\n",
       " 'classes': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.2860\u001b[0m       \u001b[32m0.9564\u001b[0m        \u001b[35m0.1422\u001b[0m     +  0.9235\n",
      "      2        \u001b[36m0.1824\u001b[0m       \u001b[32m0.9615\u001b[0m        \u001b[35m0.1225\u001b[0m     +  0.8990\n",
      "      3        \u001b[36m0.1623\u001b[0m       \u001b[32m0.9643\u001b[0m        \u001b[35m0.1154\u001b[0m     +  0.9918\n",
      "      4        \u001b[36m0.1523\u001b[0m       \u001b[32m0.9668\u001b[0m        \u001b[35m0.1107\u001b[0m     +  1.1005\n",
      "      5        \u001b[36m0.1457\u001b[0m       \u001b[32m0.9682\u001b[0m        \u001b[35m0.1072\u001b[0m     +  1.0168\n",
      "      6        \u001b[36m0.1427\u001b[0m       \u001b[32m0.9699\u001b[0m        \u001b[35m0.1043\u001b[0m     +  0.9786\n",
      "      7        \u001b[36m0.1369\u001b[0m       \u001b[32m0.9713\u001b[0m        \u001b[35m0.1019\u001b[0m     +  0.9113\n",
      "      8        \u001b[36m0.1330\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.0997\u001b[0m     +  0.8996\n",
      "      9        \u001b[36m0.1316\u001b[0m       \u001b[32m0.9744\u001b[0m        \u001b[35m0.0978\u001b[0m     +  0.9434\n",
      "     10        \u001b[36m0.1300\u001b[0m       \u001b[32m0.9751\u001b[0m        \u001b[35m0.0965\u001b[0m     +  0.9379\n",
      "     11        \u001b[36m0.1274\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.0954\u001b[0m     +  0.9181\n",
      "     12        \u001b[36m0.1260\u001b[0m       \u001b[32m0.9764\u001b[0m        \u001b[35m0.0943\u001b[0m     +  0.9204\n",
      "     13        \u001b[36m0.1252\u001b[0m       \u001b[32m0.9768\u001b[0m        \u001b[35m0.0934\u001b[0m     +  0.9210\n",
      "     14        \u001b[36m0.1249\u001b[0m       \u001b[32m0.9772\u001b[0m        \u001b[35m0.0924\u001b[0m     +  0.9474\n",
      "     15        \u001b[36m0.1234\u001b[0m       \u001b[32m0.9777\u001b[0m        \u001b[35m0.0917\u001b[0m     +  1.0088\n"
     ]
    }
   ],
   "source": [
    "net.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "dense0.weight \t torch.Size([16, 20])\n",
      "dense0.bias \t torch.Size([16])\n",
      "output.weight \t torch.Size([2, 16])\n",
      "output.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.__dict__['module_'].state_dict():\n",
    "    print(param_tensor, \"\\t\", net.__dict__['module_'].state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model's parameters:\")\n",
    "# for param_tensor in net.__dict__['module_'].parameters():\n",
    "#     print(param_tensor, \"\\t\", net.__dict__['module_'].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.5],\n",
    "    shuffle=True,\n",
    "    random_state=1)\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "y_proba = net.predict_proba(X)\n",
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_net = NeuralNetClassifier(\n",
    "#     MyModule,\n",
    "#     device='cpu',\n",
    "#     max_epochs=15,\n",
    "#     lr=0.01,\n",
    "#     # Shuffle training data on each epoch\n",
    "#     iterator_train__shuffle=True,\n",
    "#     #callbacks=[cp, train_end_cp]\n",
    "# )\n",
    "\n",
    "# new_net.initialize()\n",
    "# new_net.load_params(checkpoint=train_end_cp)\n",
    "\n",
    "# X, y = make_classification(\n",
    "#     n_samples=10,\n",
    "#     n_features=20,\n",
    "#     n_informative=5,\n",
    "#     n_classes=2,\n",
    "#     n_clusters_per_class=1,\n",
    "#     weights=[0.5],\n",
    "#     shuffle=True,\n",
    "#     random_state=1)\n",
    "\n",
    "# X = X.astype(np.float32)\n",
    "# y = y.astype(np.int64)\n",
    "\n",
    "# y_pred = new_net.predict(X)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_params(f_params='pytorch/save-params-fn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2365"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat('pytorch/save-params-fn.pkl').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=3,\n",
    "    lr=0.001,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    # callbacks=[cp, train_end_cp, load_state]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net.initialize()\n",
    "new_net.load_params(f_params='pytorch/save-params-fn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.5],\n",
    "    shuffle=True,\n",
    "    random_state=1)\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6499\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6280\u001b[0m  0.0091\n",
      "      2        0.6619       0.6250        \u001b[35m0.6266\u001b[0m  0.0103\n",
      "      3        0.6577       \u001b[32m0.6300\u001b[0m        \u001b[35m0.6252\u001b[0m  0.0101\n"
     ]
    }
   ],
   "source": [
    "new_net.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.5],\n",
    "    shuffle=True,\n",
    "    random_state=1)\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = new_net.predict_proba(X)\n",
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference model doesn't need original class, only pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(new_net, open('pytorch/dump.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7277"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat('pytorch/dump.pkl').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(open('pytorch/dump.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = loaded_model.predict_proba(X)\n",
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pytorch in a sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6922\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.8184\u001b[0m  0.0011\n",
      "      2        0.7429       0.5000        \u001b[35m0.8182\u001b[0m  0.0013\n",
      "      3        0.7381       0.5000        \u001b[35m0.8181\u001b[0m  0.0011\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', loaded_model),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "y_proba = pipe.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(pipe, open('pytorch/pipeline.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7767"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat('pytorch/pipeline.pkl').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (dense0): Linear(in_features=20, out_features=16, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (output): Linear(in_features=16, out_features=2, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipe = load(open('pytorch/pipeline.pkl', 'rb'))\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
